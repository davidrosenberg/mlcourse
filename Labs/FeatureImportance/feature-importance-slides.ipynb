{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "def hide_code_in_slideshow():\n",
    "    import os\n",
    "    uid = os.urandom(8).encode(\"hex\")\n",
    "    html = \"\"\"<div id=\"%s\"></div>\n",
    "    <script type=\"text/javascript\">\n",
    "        $(function(){\n",
    "            var p = $(\"#%s\");\n",
    "            if (p.length==0) return;\n",
    "\n",
    "            while (!p.hasClass(\"cell\")) {\n",
    "                p=p.parent();\n",
    "\n",
    "                if (p.prop(\"tagName\") ==\"body\") return;\n",
    "            }\n",
    "            var cell = p;\n",
    "            cell.find(\".input\").addClass(\"hide-in-slideshow\")\n",
    "        });\n",
    "    </script>\"\"\" % (uid, uid)\n",
    "    display.display_html(html, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Feature Importance outline\n",
    "\n",
    "### Feature importance\n",
    "- Introduction and motivation for discussing feature importance:\n",
    "    - Define feature importance (using a fuzzy definition -- rank features by how much they \"*contribute*\" to the prediction function).\n",
    "    - Feature importance measures are frequently reported, in part because many packages make them easy to compute/visualize.\n",
    "        - Show google image search results\n",
    "    - They can be potentially misleading. Important to understand potential pitfalls.\n",
    "    - Utility of feature importance:\n",
    "        - Feature selection -- use votes example from original Breiman Random Forests paper.\n",
    "        - Sanity checking models/detecting leakage (TODO: see if I can find an example where feature importance show some feature unexpectedly popping since due to leakage).\n",
    "- Framing feature importance methods:\n",
    "    - Divide into two classes:\n",
    "        - Methods that exploit the structure of the prediction function or learning algorithm (call these function-specific).\n",
    "        - Methods that are agnostic (i.e. can be applied to any black box prediction function).\n",
    "- Function-specific methods:\n",
    "    - Mean decrease impurity:\n",
    "        - Frame running example:\n",
    "            - Introduce the iris dataset and classification problem.\n",
    "            - graphviz some shallow tree on the iris dataset (see below).\n",
    "            - **Ask students** which features seem \"important\" as a turn and talk. Have some subset share answers without explanation.\n",
    "        - Introduce MDE:\n",
    "        $$Imp(X_m) = \\frac{1}{N_T}\\sum_T\\sum_{t \\in T:v(s_t)=X_m}p(t)\\Delta i(s_t,t)$$\n",
    "        - Show from scratch implimentation (see lab_outline_and_mean_decrease_impurity.ipynb).\n",
    "        - Show correspondance with sklearn's implementation.\n",
    "        - **Ask students** what other classifiers we could extend this too (Random Forests/GBMs) and how (averaging).\n",
    "        - Show RF importance for the iris problem.\n",
    "        - Say there are variants:\n",
    "            - Example: CART implementation exposes a knob to add weight for use of a feature as a surrogate split.\n",
    "    - Absolute coefficients in a linear model:\n",
    "        - **Ask students** how we could determine feature importance in a linear model.\n",
    "        - Show some example (TODO) of extracting absolute $\\beta$s from a model.\n",
    "        - **Ask students**: How would this interact with preprocessing?\n",
    "- Model agnostic methods:\n",
    "    - Frame the general problem for global feature importance:\n",
    "        - Another framing of feature importance -- we are trying to identify how much each feature independently contributes to risk reduction in the learned model.\n",
    "        - **Ask students**: How could we do this for an arbitrary black box prediction function?\n",
    "        - **Hint (fragment slide)**: Imagine you were tasked with constructing a synthetic dataset with an *unimportant* feature -- how could you construct it? Given this insight, what operation could be applied to a feature that would be expected to have (a) no impact on empirical risk for unimportant features, and (b) decrease performance for important featuers?\n",
    "    - Permutation importance:\n",
    "        - Give Breimans original OOB permutation feature importance.\n",
    "        - Say that the OOB version exploits bootstrapping in RFs, but can just use a validation set.\n",
    "        - Show example (using ELI5 implementation) over the iris problem.\n",
    "        - **Ask students**: This method permute features to get a measure of feature importance. Let's extend this concept a bit -- how could permuting the target be useful in interogating the performance of a model?\n",
    "        - http://jmlr.csail.mit.edu/papers/volume11/ojala10a/ojala10a.pdf\n",
    "        - For fun show this using permutation_test_score for the iris data.\n",
    "- Pitfalls:\n",
    "    - Correlated features\n",
    "        - Show the GBM feature importance for duplicated or highly correlated features (TODO: think about which is better for this purpose) (from lab_outline_and_mean_decrease_impurity.ipynb).\n",
    "        - **Ask students**: Interpret this plot. What can we say about the features/model?\n",
    "        - Show same plot for enet, and ask same question -- hopefully students will recall that (at least in the context of linear models) our conversations about feature correlation.\n",
    "        - Show the elastnic net bound result as review, and primer to think about correlation issues.\n",
    "        - Show correlation matrix/matrices (duplicated and/or highly correlated), and known data generating process.\n",
    "        - **Ask students**: Given what we know about (i) linear methods, and (ii) trees, what does this show us about potential pitfalls in interpreting feature importance plots?\n",
    "        - **Ask students**: How would this impact SelectFromModel feature selection procedures (ala sklearn) which select the most important features from a model based on either absolute coefficients or feature importance scores? Why might we want to use RFE?\n",
    "\n",
    "### PDPs\n",
    "- Motivation and introduction to partial dependence plots\n",
    "    - Imagine we have a subset of features we think are important.\n",
    "        - This could be based on \"feature importance\" scores or coefficients, or other reasons (i.e. prior knowledge/research questions/etc.).\n",
    "    - We may want to dig deeper to explain the relationship between our predictions and these features.\n",
    "        - **Ask students**: Why? If we have MDI feature importance scores in hand, what do we not know?\n",
    "            - Directionality:\n",
    "                - Note in reality we probably have complex, non-monotonic relationships\n",
    "                - However even if we have a monotonic relationship, or even linear, our MDI wouldn't give any indication on the direction -- obviously weights in a linear model would.\n",
    "    - Partial dependence plots let us dig deeper and visualize the dependence of our prediction function (i.e. predict/predict_proba) on one or two of these features. Can't easily go higher-dimensional (Why not? Can't visualize).\n",
    "    - Show basic math (marginal and empirical estimate -- see https://arxiv.org/pdf/1309.6392.pdf for useful framing).\n",
    "\n",
    "- PDP examples:\n",
    "    - Show sklearn example (see partial_dependence.ipynb).\n",
    "    - **Ask students**: What does this plot show? How do we interpret it? \n",
    "- PDP pitfalls:\n",
    "    - Show the flat partial dependence plot from (https://arxiv.org/pdf/1309.6392.pdf) reproduced in partial_dependence.ipynb.\n",
    "    - **Ask students**: What does this plot show?\n",
    "    - Follow up with big reveal:\n",
    "        - Show data generating process and X plot.\n",
    "    - **Ask students**: What does this teach us? When might PDPs fail?\n",
    "    - Share \"not too strong\" quote from Friedman's original work (see partial_dependence.ipynb).\n",
    "    \n",
    "### Additional material\n",
    "- If 100 minutes allows (what is your opinion, David?), the next steps would be:\n",
    "    - Generate the ICE plot for the X data (figure 2 in https://arxiv.org/pdf/1309.6392.pdf)\n",
    "    - Take this  as a launching point for point out that our progression has been from:\n",
    "        - Global measures (feature importance) that don't necessarily describe structure (even directionality) of a relationship between a feature and target.\n",
    "        - Marginalized measures showing average relationship between one or two features and the target.\n",
    "        - Data-instance specific feature importance plots showing the importance of a feature, for each data instance, fixing all other feature values.\n",
    "    - We can follow this thread it's conclusion -- attempting to develop model explanations that show the relative contribution of each feature to predictions locally (i.e. in the neighborhood of a specific instance):\n",
    "        - LIME paper (https://arxiv.org/abs/1602.04938) as one example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <h1>Feature Importance</h1>\n",
    "    <h4>\n",
    "        Ben Jakubowski <br>\n",
    "        NYU <br>\n",
    "        April 18th, 2018 <br>\n",
    "    </h4>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning objectives\n",
    "- (Informally) define feature importance, and explain why exploring and presenting feature importance can be both (i) useful, and (ii) potentially misleading.\n",
    "- Define and describe several feature importance methods that exploit the structure of the learning algorithm or learned prediction function.\n",
    "- Describe a prediction-function-agnostic method for generating feature importance scores.\n",
    "- Describe the limitations of these feature importance measures and understand cases where they \"fail\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Defining feature importance\n",
    "- Problem setup -- we have some data $(x, y) \\in (\\mathbb{R}^{d}, \\mathcal{Y})$, and a learned prediction function $f$.\n",
    "- A feature importance method can be loosely understood as a function that maps each feature onto some score.\n",
    "- These scores rank features by how much they \"*contribute*\" to the prediction function $f$.\n",
    "    - Here \"*contribute*\" is defined separately for each method.\n",
    "    - In general, *feature importance* is not consistently or rigorously defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why we need to discuss feature importance\n",
    "- It is easy to compute feature importance from many ML libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Google \"feature importance\" image search results](./static/google.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why we need to discuss feature importance\n",
    "- It is easy to compute feature importance from many ML libraries.\n",
    "- This means feature importance bar charts show up all over, and it is important to understand:\n",
    "    - How feature importance can be computed.\n",
    "    - Potential pitfalls in over interpreting these scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Utility of feature importance scores\n",
    "- Why might feature importance scores be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Use for sanity checking a model -- do the features that are important seem reasonable, or do they suggest something strange is going on under the hood (i.e. leakage)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Share with clients/bosses to build trust and get buy-in on the prediction function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Use for feature selection -- can extract the top $K$ features and retrain over this subset (ex: `sklearn.feature_selection.SelectFromModel`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature selection example\n",
    "- Breiman's original Random Forests paper showed feature importance for classification of political party based on 16 votes<sup id=\"a1\">[1](https://link.springer.com/content/pdf/10.1023/A:1010933404324.pdf)</sup>:\n",
    "![Breiman's voting feature importance plot](./static/breiman_votes.png)\n",
    "- *'We reran this data set using only variable 4. The test set error is 4.3%, about the same as if all variables were used.'*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### First example/introducing the  issues\n",
    "\n",
    "- Consider the following feature importance plot for a regression problem with $$\\mathcal{Y} = \\mathcal{A} = \\mathbb{R}, X = \\mathbb{R}^{11}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"30e3a56bc992bb7b\"></div>\n",
       "    <script type=\"text/javascript\">\n",
       "        $(function(){\n",
       "            var p = $(\"#30e3a56bc992bb7b\");\n",
       "            if (p.length==0) return;\n",
       "\n",
       "            while (!p.hasClass(\"cell\")) {\n",
       "                p=p.parent();\n",
       "\n",
       "                if (p.prop(\"tagName\") ==\"body\") return;\n",
       "            }\n",
       "            var cell = p;\n",
       "            cell.find(\".input\").addClass(\"hide-in-slideshow\")\n",
       "        });\n",
       "    </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hide_code_in_slideshow()\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook', font_scale=1.5)\n",
    "%matplotlib inline\n",
    "\n",
    "X,y = make_regression(n_samples=1000, n_features=10,\n",
    "                      n_informative=3,random_state=1234,\n",
    "                      shuffle=False, noise=10)\n",
    "X = np.append(X, X[:,[0]], axis=1)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1235)\n",
    "\n",
    "enet = ElasticNetCV(l1_ratio=np.array([.1, .5, .7, .9, .95, .99, 1]),\n",
    "                    n_alphas=500,\n",
    "                    normalize=True,\n",
    "                    selection='random',\n",
    "                    random_state=1351)\n",
    "enet.fit(train_X, train_y)\n",
    "\n",
    "coefs = pd.DataFrame({'Feature': np.arange(len(enet.coef_)),\n",
    "                      'Importance': np.abs(enet.coef_)})\n",
    "coefs = coefs.set_index('Feature')\\\n",
    "             .sort_values('Importance', ascending=False)\n",
    "    \n",
    "fig, ax=plt.subplots(figsize=(12,6))\n",
    "plot = coefs.plot(kind='bar', title='Typical feature importance chart', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Question: What can we say about this prediction function, it features, and target?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### First example/introducing the  issues (continued)\n",
    "\n",
    "- Recall the full feature set includes features $\\{0,\\cdots,10\\}$.\n",
    "- Let's compare both (a) test set performance ($R^2$), and (b) feature importance plots, for models trained on:\n",
    "    - All features\n",
    "    - Features $\\{0,\\cdots,9\\}$\n",
    "    - Features $\\{1,\\cdots,9\\}$\n",
    "    - Features $\\{1,\\cdots,10\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### First example/introducing the  issues (continued)\n",
    "\n",
    "- Recall the full feature set includes features $\\{0,\\cdots,10\\}$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"7dd89705abf0bccd\"></div>\n",
       "    <script type=\"text/javascript\">\n",
       "        $(function(){\n",
       "            var p = $(\"#7dd89705abf0bccd\");\n",
       "            if (p.length==0) return;\n",
       "\n",
       "            while (!p.hasClass(\"cell\")) {\n",
       "                p=p.parent();\n",
       "\n",
       "                if (p.prop(\"tagName\") ==\"body\") return;\n",
       "            }\n",
       "            var cell = p;\n",
       "            cell.find(\".input\").addClass(\"hide-in-slideshow\")\n",
       "        });\n",
       "    </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import floor\n",
    "\n",
    "hide_code_in_slideshow()\n",
    "features_to_test = {\n",
    "    'All': np.arange(0,11),\n",
    "    '0-9': np.arange(0,10),\n",
    "    '1-9': np.arange(1,10),\n",
    "    '1-10': np.arange(1,11)\n",
    "}\n",
    "\n",
    "fig, axarr = plt.subplots(ncols=2, nrows=2, figsize=(12,8))\n",
    "\n",
    "i = 0\n",
    "for model_name, features in features_to_test.items():\n",
    "    col = i % 2\n",
    "    row = int(floor(i/2))\n",
    "    \n",
    "    _train_X = train_X[:, features]\n",
    "    _test_X = test_X[:, features]\n",
    "    \n",
    "    enet = ElasticNetCV(l1_ratio=np.array([.1, .5, .7, .9, .95, .99, 1]),\n",
    "                        n_alphas=1000,\n",
    "                        normalize=True,\n",
    "                        selection='random',\n",
    "                        random_state=1351)\n",
    "    enet.fit(_train_X, train_y)\n",
    "\n",
    "    coefs = pd.DataFrame({'Feature': features,\n",
    "                          'Importance': np.abs(enet.coef_)})\n",
    "    coefs = coefs.set_index('Feature')\\\n",
    "                 .sort_values('Importance', ascending=False)\n",
    "\n",
    "    plot = coefs.plot(kind='bar', title='Typical feature importance chart', ax=axarr[(row,col)])\n",
    "    \n",
    "    title = 'Features:' + model_name + r'; $R^2$ =' + \\\n",
    "             str(round(enet.score(_test_X,test_y),3))\n",
    "    \n",
    "    axarr[(row,col)].set_title(title)\n",
    "    \n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What can we learn from this example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### First example/introducing the  issues (continued)\n",
    "\n",
    "- Here was the setup:\n",
    "```\n",
    "X,y = make_regression(n_samples=1000, n_features=10,\n",
    "                      n_informative=3,random_state=1234,\n",
    "                      shuffle=False, noise=10)\n",
    "X = np.append(X, X[:,[0]], axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some things to keep in mind:\n",
    "    - Interactions and correlated/dependent features makes intepretation tricky.\n",
    "    - Feature importance $\\ne$ dependence of target on feature\n",
    "    - Feature importance $\\approx$ contribution of feature to prediction function $f$\n",
    "    - **This doesn't imply there do not exist other functions $f'$ where features that are 'unimportant' in $f$ are 'important'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Where we're headed:\n",
    "- With this in mind, we're going to look at a number of methods for measuring feature importance.\n",
    "- We can devide these methods into two basic classes:\n",
    "    - Algorithmic/prediction-function-specific methods: These exploit the structure of the learning algorithm/prediction function to construct some measure of the relative contribution of each feature.\n",
    "    - Model agnostic methods: These don't make assumptions on the algorithm or structure of the prediction function; can be applied to any black-box predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction-function-specific: Trees\n",
    "\n",
    "- Our first algorithm/prediction function specific methods will address decision trees.\n",
    "- We'll use the Iris Dataset, which is a canonical classification dataset (first used by R.A. Fisher) with:\n",
    "    - $\\mathcal{Y} = $ {Setosa, Versicolour, Virginica} (three varieties of irises).\n",
    "    - $X = $ [sepal length, sepal width, petal length, petal width] $\\in \\mathbb{R}^4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prediction-function-specific: Trees (Continued)\n",
    "\n",
    "- Let's consider a shallow tree built on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"17233d8b75b0d5d2\"></div>\n",
       "    <script type=\"text/javascript\">\n",
       "        $(function(){\n",
       "            var p = $(\"#17233d8b75b0d5d2\");\n",
       "            if (p.length==0) return;\n",
       "\n",
       "            while (!p.hasClass(\"cell\")) {\n",
       "                p=p.parent();\n",
       "\n",
       "                if (p.prop(\"tagName\") ==\"body\") return;\n",
       "            }\n",
       "            var cell = p;\n",
       "            cell.find(\".input\").addClass(\"hide-in-slideshow\")\n",
       "        });\n",
       "    </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"560pt\" height=\"414pt\"\n",
       " viewBox=\"0.00 0.00 559.83 414.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 410)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-410 555.831,-410 555.831,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M267.357,-406C267.357,-406 128.398,-406 128.398,-406 122.398,-406 116.398,-400 116.398,-394 116.398,-394 116.398,-340 116.398,-340 116.398,-334 122.398,-328 128.398,-328 128.398,-328 267.357,-328 267.357,-328 273.357,-328 279.357,-334 279.357,-340 279.357,-340 279.357,-394 279.357,-394 279.357,-400 273.357,-406 267.357,-406\"/>\n",
       "<text text-anchor=\"start\" x=\"124.388\" y=\"-390.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm)  2.45</text>\n",
       "<text text-anchor=\"start\" x=\"161.486\" y=\"-376.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.667</text>\n",
       "<text text-anchor=\"start\" x=\"152.155\" y=\"-362.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150</text>\n",
       "<text text-anchor=\"start\" x=\"138.138\" y=\"-348.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 50, 50]</text>\n",
       "<text text-anchor=\"start\" x=\"153.328\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M167.784,-285C167.784,-285 71.9712,-285 71.9712,-285 65.9712,-285 59.9712,-279 59.9712,-273 59.9712,-273 59.9712,-233 59.9712,-233 59.9712,-227 65.9712,-221 71.9712,-221 71.9712,-221 167.784,-221 167.784,-221 173.784,-221 179.784,-227 179.784,-233 179.784,-233 179.784,-273 179.784,-273 179.784,-279 173.784,-285 167.784,-285\"/>\n",
       "<text text-anchor=\"start\" x=\"91.2725\" y=\"-269.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"78.0483\" y=\"-255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n",
       "<text text-anchor=\"start\" x=\"67.9243\" y=\"-241.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 0, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"75.3276\" y=\"-227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171.252,-327.769C163.515,-316.66 155.053,-304.509 147.27,-293.333\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"150.061,-291.216 141.474,-285.01 144.317,-295.216 150.061,-291.216\"/>\n",
       "<text text-anchor=\"middle\" x=\"137.07\" y=\"-305.419\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M343.396,-292C343.396,-292 210.359,-292 210.359,-292 204.359,-292 198.359,-286 198.359,-280 198.359,-280 198.359,-226 198.359,-226 198.359,-220 204.359,-214 210.359,-214 210.359,-214 343.396,-214 343.396,-214 349.396,-214 355.396,-220 355.396,-226 355.396,-226 355.396,-280 355.396,-280 355.396,-286 349.396,-292 343.396,-292\"/>\n",
       "<text text-anchor=\"start\" x=\"206.119\" y=\"-276.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm)  1.75</text>\n",
       "<text text-anchor=\"start\" x=\"248.272\" y=\"-262.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"231.155\" y=\"-248.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n",
       "<text text-anchor=\"start\" x=\"221.031\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 50, 50]</text>\n",
       "<text text-anchor=\"start\" x=\"223\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M224.844,-327.769C231.072,-318.939 237.765,-309.451 244.207,-300.318\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"247.129,-302.248 250.033,-292.058 241.409,-298.213 247.129,-302.248\"/>\n",
       "<text text-anchor=\"middle\" x=\"254.289\" y=\"-312.494\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.898039\" stroke=\"black\" d=\"M256.357,-178C256.357,-178 117.398,-178 117.398,-178 111.398,-178 105.398,-172 105.398,-166 105.398,-166 105.398,-112 105.398,-112 105.398,-106 111.398,-100 117.398,-100 117.398,-100 256.357,-100 256.357,-100 262.357,-100 268.357,-106 268.357,-112 268.357,-112 268.357,-166 268.357,-166 268.357,-172 262.357,-178 256.357,-178\"/>\n",
       "<text text-anchor=\"start\" x=\"113.388\" y=\"-162.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm)  4.95</text>\n",
       "<text text-anchor=\"start\" x=\"150.486\" y=\"-148.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.168</text>\n",
       "<text text-anchor=\"start\" x=\"145.048\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\n",
       "<text text-anchor=\"start\" x=\"134.924\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 49, 5]</text>\n",
       "<text text-anchor=\"start\" x=\"133\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M246.156,-213.769C238.988,-204.849 231.281,-195.257 223.872,-186.038\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"226.452,-183.661 217.46,-178.058 220.996,-188.046 226.452,-183.661\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.976471\" stroke=\"black\" d=\"M437.357,-178C437.357,-178 298.398,-178 298.398,-178 292.398,-178 286.398,-172 286.398,-166 286.398,-166 286.398,-112 286.398,-112 286.398,-106 292.398,-100 298.398,-100 298.398,-100 437.357,-100 437.357,-100 443.357,-100 449.357,-106 449.357,-112 449.357,-112 449.357,-166 449.357,-166 449.357,-172 443.357,-178 437.357,-178\"/>\n",
       "<text text-anchor=\"start\" x=\"294.388\" y=\"-162.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm)  4.85</text>\n",
       "<text text-anchor=\"start\" x=\"331.486\" y=\"-148.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.043</text>\n",
       "<text text-anchor=\"start\" x=\"326.048\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n",
       "<text text-anchor=\"start\" x=\"315.924\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 45]</text>\n",
       "<text text-anchor=\"start\" x=\"318.276\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M307.94,-213.769C315.188,-204.849 322.981,-195.257 330.471,-186.038\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"333.365,-188.027 336.955,-178.058 327.933,-183.613 333.365,-188.027\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.980392\" stroke=\"black\" d=\"M111.633,-64C111.633,-64 12.1223,-64 12.1223,-64 6.12232,-64 0.122316,-58 0.122316,-52 0.122316,-52 0.122316,-12 0.122316,-12 0.122316,-6 6.12232,-0 12.1223,-0 12.1223,-0 111.633,-0 111.633,-0 117.633,-0 123.633,-6 123.633,-12 123.633,-12 123.633,-52 123.633,-52 123.633,-58 117.633,-64 111.633,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"25.4863\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.041</text>\n",
       "<text text-anchor=\"start\" x=\"20.0483\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 48</text>\n",
       "<text text-anchor=\"start\" x=\"9.92432\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 47, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.396,-99.7956C130.053,-90.2671 117.899,-80.0585 106.593,-70.5614\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.83,-67.8692 98.9217,-64.1172 104.328,-73.2291 108.83,-67.8692\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.498039\" stroke=\"black\" d=\"M244.581,-64C244.581,-64 153.174,-64 153.174,-64 147.174,-64 141.174,-58 141.174,-52 141.174,-52 141.174,-12 141.174,-12 141.174,-6 147.174,-0 153.174,-0 153.174,-0 244.581,-0 244.581,-0 250.581,-0 256.581,-6 256.581,-12 256.581,-12 256.581,-52 256.581,-52 256.581,-58 250.581,-64 244.581,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"162.486\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"start\" x=\"160.941\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n",
       "<text text-anchor=\"start\" x=\"150.817\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 4]</text>\n",
       "<text text-anchor=\"start\" x=\"149.276\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M191.244,-99.7956C192.197,-91.4581 193.209,-82.6 194.174,-74.1534\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"197.663,-74.4499 195.321,-64.1172 190.708,-73.6551 197.663,-74.4499\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.498039\" stroke=\"black\" d=\"M401.581,-64C401.581,-64 310.174,-64 310.174,-64 304.174,-64 298.174,-58 298.174,-52 298.174,-52 298.174,-12 298.174,-12 298.174,-6 304.174,-0 310.174,-0 310.174,-0 401.581,-0 401.581,-0 407.581,-0 413.581,-6 413.581,-12 413.581,-12 413.581,-52 413.581,-52 413.581,-58 407.581,-64 401.581,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"319.486\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"start\" x=\"317.941\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"307.817\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"306.276\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M363.511,-99.7956C362.558,-91.4581 361.546,-82.6 360.581,-74.1534\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"364.047,-73.6551 359.434,-64.1172 357.092,-74.4499 364.047,-73.6551\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M539.784,-64C539.784,-64 443.971,-64 443.971,-64 437.971,-64 431.971,-58 431.971,-52 431.971,-52 431.971,-12 431.971,-12 431.971,-6 437.971,-0 443.971,-0 443.971,-0 539.784,-0 539.784,-0 545.784,-0 551.784,-6 551.784,-12 551.784,-12 551.784,-52 551.784,-52 551.784,-58 545.784,-64 539.784,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"463.272\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"450.048\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 43</text>\n",
       "<text text-anchor=\"start\" x=\"439.924\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 43]</text>\n",
       "<text text-anchor=\"start\" x=\"442.276\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M412.995,-99.7956C424.14,-90.3587 436.072,-80.2547 447.196,-70.8355\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"449.76,-73.2504 455.13,-64.1172 445.236,-67.9083 449.76,-73.2504\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x10d9e8990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hide_code_in_slideshow()\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                                feature_names=iris.feature_names,  \n",
    "                                class_names=iris.target_names,  \n",
    "                                filled=True, rounded=True,  \n",
    "                                special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "display.display(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Which of the feature ([sepal length, sepal width, petal length, petal width]) are most important? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prediction-function-specific: Trees (Continued)\n",
    "\n",
    "#### Tree buiding reminders\n",
    "- Consider node $t$ in a decision tree built on $N$ training data instances.\n",
    "- Let node $t$ have $N_t$ node samples.\n",
    "- We find the split $s_t$ at node $t$ such that $t_L$ and $t_R$ maximizes the decrease\n",
    "$$\\Delta i(s, t) = i(t)  p_Li(t_L)  p_Ri(t_R)$$\n",
    "where $p_L$ and $p_R$ are the probabilities an instance splits left and right, respectively, and $i(t)$ is some some impurity measure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Mean decrease impurity\n",
    "- The **mean decrease impurity** $imp(X_m)$ for feature $X_m$ is:\n",
    "$$imp(X_m) = \\sum_{v(s_t)=X_m}p(t)\\Delta i(s_t,t)$$\n",
    "Note $p(t) = N_t/N$ is the proportion of samples reaching node $t$ and $v(s_t)$ is the variable used in split $s_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prediction-function-specific: Trees (Continued)\n",
    "\n",
    "$$imp(X_m) = \\sum_{v(s_t)=X_m}p(t)\\Delta i(s_t,t)$$\n",
    "\n",
    "- **Question**: When will a feature be considered more important under this metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Why is this an algorithm/prediction-function specific method?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prediction-function-specific: Trees (Continued)\n",
    "\n",
    "- Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def feature_importance_single_tree(tree, feature_names=iris.feature_names):\n",
    "    # Returns normed feature importance for a single sklearn.tree\n",
    "    # Note sklearn tree's can handle instance weights, so we need\n",
    "    # to use weighted_n_node_samples\n",
    "    \n",
    "    total_samples = np.sum(tree.weighted_n_node_samples)\n",
    "    feature_importance = defaultdict(float)\n",
    "    \n",
    "    # Identify leaves as described in sklearn's plot_unveil_tree_structure.html\n",
    "    is_leaf = (tree.children_right == tree.children_left)\n",
    "    for ix in range(len(is_leaf)):\n",
    "        if not is_leaf[ix]:\n",
    "            impurity = tree.impurity[ix]\n",
    "            split_feature = tree.feature[ix]\n",
    "            num_at_node = tree.weighted_n_node_samples[ix]\n",
    "\n",
    "            # Get left child contribution\n",
    "            left_child = tree.children_left[ix]\n",
    "            left_decrease = tree.weighted_n_node_samples[left_child]/num_at_node * \\\n",
    "                                tree.impurity[left_child]\n",
    "\n",
    "            # Get right child contribution\n",
    "            right_child = tree.children_right[ix]\n",
    "            right_decrease = tree.weighted_n_node_samples[right_child]/num_at_node * \\\n",
    "                                tree.impurity[right_child]\n",
    "\n",
    "            delta = impurity - left_decrease - right_decrease\n",
    "            \n",
    "            feature_importance[feature_names[split_feature]] \\\n",
    "                += num_at_node / total_samples * delta\n",
    "    norm = np.sum(feature_importance.values())\n",
    "    feature_importance = {key: val/norm for key, val in feature_importance.items()}\n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prediction-function-specific: Trees (Continued)\n",
    "\n",
    "- Implementation vs. sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>0.585616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>0.414384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Importance\n",
       "0  petal length (cm)    0.585616\n",
       "1   petal width (cm)    0.414384"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp = feature_importance_single_tree(clf.tree_)\n",
    "display.display(pd.Series(imp).rename('Importance').to_frame()\\\n",
    "                  .reset_index().rename(columns={'index':'Feature'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>0.585616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>0.414384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal width (cm)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Importance\n",
       "2  petal length (cm)    0.585616\n",
       "3   petal width (cm)    0.414384\n",
       "0  sepal length (cm)    0.000000\n",
       "1   sepal width (cm)    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display(pd.DataFrame({'Feature': iris.feature_names,\n",
    "                              'Importance':clf.feature_importances_})\\\n",
    "                  .sort_values('Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prediction-function-specific: Trees (Continued)\n",
    "\n",
    "- **Question**: How do we extend this to ensembles of trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer**: (Weighted) averages.\n",
    "    - Ex: Random Forests with $N_T$ trees:\n",
    "    \n",
    "$$Imp(X_m) = \\frac{1}{N_T}\\sum_T\\sum_{t \\in T:v(s_t)=X_m}p(t)\\Delta i(s_t,t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prediction-function-specific: Trees (Continued)\n",
    "\n",
    "- Implementation vs. sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>0.454194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>0.433065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>0.091797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal width (cm)</td>\n",
       "      <td>0.020943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Importance\n",
       "3   petal width (cm)    0.454194\n",
       "2  petal length (cm)    0.433065\n",
       "0  sepal length (cm)    0.091797\n",
       "1   sepal width (cm)    0.020943"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100) # Not tuned - just example\n",
    "forest.fit(iris.data, iris.target)\n",
    "display.display(pd.DataFrame({'Feature': iris.feature_names,\n",
    "                              'Importance':forest.feature_importances_})\\\n",
    "                  .sort_values('Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>0.454194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>0.433065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>0.091797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sepal width (cm)</td>\n",
       "      <td>0.020943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Importance\n",
       "1   petal width (cm)    0.454194\n",
       "0  petal length (cm)    0.433065\n",
       "2  sepal length (cm)    0.091797\n",
       "3   sepal width (cm)    0.020943"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest_importance = defaultdict(float)\n",
    "for tree in forest.estimators_:\n",
    "    tree_importance = feature_importance_single_tree(tree.tree_)\n",
    "    \n",
    "    for key, val in tree_importance.items():\n",
    "        forest_importance[key] += val\n",
    "forest_importance = {key:val/len(forest.estimators_)\\\n",
    "                     for key, val in forest_importance.items()}\n",
    "\n",
    "display.display(pd.Series(forest_importance).rename('Importance').to_frame()\\\n",
    "                  .reset_index().rename(columns={'index':'Feature'})\\\n",
    "                  .sort_values('Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prediction-function-specific: Trees (Continued)\n",
    "\n",
    "- Variants:\n",
    "    - Commercial implementation of [CART](https://www.salford-systems.com/support/faq/cart/what-is-variable-importance) adds contributions of surrogate splits to feature importance.\n",
    "    - **Question**: Can we think of any other variants or extensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Consider collapsing the importance of dummy-encoded categoricals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction-function-specific: Linear models\n",
    "\n",
    "- **Question**: How can we measure feature importance in a linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$imp(X_m) = \\big\\vert w_m \\big\\vert$$\n",
    "- **Question**: Per usual, how does this notion of importance interact with preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model-agnostic feature importance:\n",
    "\n",
    "- We've discussed two methods for algorithm or prediction-function specific feature importance measures:\n",
    "    - Trees (and their ensembles): Mean Decrease Impurity\n",
    "    - Linear methods: Absolute weights\n",
    "- **Question**: How could we determine the importance of input features for an arbitrary black box prediction function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Hint 1: Think about defining importance as by measuring how much each feature independently contributes to the performance of the learned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Hint 2: Imagine you were tasked with constructing a synthetic dataset with an unimportant feature -- how could you construct it? Given this insight, what operation could be applied to a feature that would be expected to have (a) no impact on the test set score for unimportant features, and (b) decrease performance for important features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model-agnostic feature importance:\n",
    "\n",
    "##### Permutation Importance\n",
    "\n",
    "- Described by Breiman in the original Random Forests paper (using OOB sample).\n",
    "- We describe it using an arbitrary held-out test set:\n",
    "\n",
    "  1. Learn prediction function $f$ on training data.\n",
    "  2. Measure the performance of $f$ on the test set - call this $s_{0}$.\n",
    "  3. For each feature $i$ in $[1,\\cdots,D]$:\n",
    "    1. Permute just this feature in the test set.\n",
    "    2. Pass this permuted test set through $f$ to obtain a new score $s_{i}$.\n",
    "  4. Use either $s_{0} - s_{i}$ (or some appropriate variant on this idea) as feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model-agnostic feature importance:\n",
    "\n",
    "##### Permutation Importance\n",
    "\n",
    "- **Question**: Why bother permuting the feature? Why not just drop it entirely?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Why bother permuting the feature? Why not replace it with some noise, like $\\mathcal{N}(0,1)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model-agnostic feature importance:\n",
    "\n",
    "##### Permutation Importance\n",
    "\n",
    "- **Question**: Is this any different than the following procedure? If so, how?\n",
    "\n",
    "  1. Learn prediction function $f$ on training data.\n",
    "  2. Measure the performance of $f$ on the test set - call this $s_{0}$.\n",
    "  3. For each feature $i$ in $[1,\\cdots,D]$:\n",
    "    1. Drop this feature from both the training and the test set.\n",
    "    2. Learn a new prediction function without this feature -- call this function $f_{\\setminus i}$\n",
    "    3. Measure the performance of $f_{\\setminus i}$ on the test set to obtain a new score $s_{i}$.\n",
    "  4. Use either $s_{0} - s_{i}$ as feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key difference**: Permutation importance (plus $\\big\\vert w \\big \\vert$ and MDI) describe the importance of each feature to a particular prediction function $f$, **not** the dependence of the target on that feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature importance pitfalls:\n",
    "\n",
    "- To conclude our discussion of feature importance, we're going to look at an example to understand potential pitfalls.\n",
    "- We will compare:\n",
    "    - Permutation importance\n",
    "    - MDI for a gradient boosting regressor\n",
    "    - $\\big\\vert w \\big\\vert$ for an elastic net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature importance pitfalls: Problem set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "size = 1000\n",
    "x1 = np.random.uniform(-10,10,size)\n",
    "z1 = np.random.uniform(-10,10,size)\n",
    "x2 = z1 + np.random.normal(0,2,size)\n",
    "x3 = z1 + np.random.normal(0,2,size)\n",
    "x4 = z1 + np.random.normal(0,2,size)\n",
    "\n",
    "def actual_function(x1,z1):\n",
    "    return -1./2.*x1 + z1 + np.random.normal(0,1,len(x1))\n",
    "\n",
    "y = actual_function(x1,z1)\n",
    "X = np.stack([x1,x2,x3,x4]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Which feature is most important (i.e. contributes most to the true conditional mean function)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature importance pitfalls: Prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=0.2,\n",
    "                                                    random_state=1345134)\n",
    "reg = GradientBoostingRegressor(n_estimators=200,subsample=0.5,\n",
    "                                random_state=3141)\n",
    "grid = GridSearchCV(reg,\n",
    "                    param_grid={\n",
    "                        'max_leaf_nodes':[10,25,50],\n",
    "                        'min_samples_leaf':[10,25,50]\n",
    "                    }, n_jobs=5, cv=5)\n",
    "grid = grid.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$x_1$</td>\n",
       "      <td>0.259480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$x_2$</td>\n",
       "      <td>0.261315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$x_3$</td>\n",
       "      <td>0.218782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$x_4$</td>\n",
       "      <td>0.260423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Importance\n",
       "0   $x_1$    0.259480\n",
       "1   $x_2$    0.261315\n",
       "2   $x_3$    0.218782\n",
       "3   $x_4$    0.260423"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython import display\n",
    "display.display(pd.DataFrame({'Feature': ['$x_{}$'.format(i) for i in range(1,5)],\n",
    "                              'Importance':grid.best_estimator_.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.3749\n",
       "                \n",
       "                    &plusmn; 0.0398\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2665\n",
       "                \n",
       "                    &plusmn; 0.0343\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.63%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1674\n",
       "                \n",
       "                    &plusmn; 0.0278\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.74%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1445\n",
       "                \n",
       "                    &plusmn; 0.0107\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(grid)\n",
    "perm.fit(test_X, test_y)\n",
    "display.display(eli5.show_weights(perm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next steps\n",
    "- While partial dependence plots give some insight into local structure of prediction function (after marginalizing), there are methods for more local model explainations (i.e. around a specific data instance).\n",
    "- See, for example, [LIME](https://arxiv.org/pdf/1602.04938.pdf).\n",
    "- This is a area capturing lots of peoples interest (especially people in the fair, accountable, transparent ML community)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "livereveal": {
   "scroll": true,
   "theme": "white",
   "transition": "slide"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
