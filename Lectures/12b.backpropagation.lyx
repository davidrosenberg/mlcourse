#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass beamer
\begin_preamble
\usetheme{CambridgeUS} 
\beamertemplatenavigationsymbolsempty


% Set Color ==============================
\definecolor{NYUPurple}{RGB}{87,6,140}
\definecolor{LightPurple}{RGB}{165,11,255}


\setbeamercolor{title}{fg=NYUPurple}
%\setbeamercolor{frametitle}{fg=NYUPurple}
\setbeamercolor{frametitle}{fg=NYUPurple}

\setbeamercolor{background canvas}{fg=NYUPurple, bg=white}
\setbeamercolor{background}{fg=black, bg=NYUPurple}

\setbeamercolor{palette primary}{fg=black, bg=gray!30!white}
\setbeamercolor{palette secondary}{fg=black, bg=gray!20!white}
\setbeamercolor{palette tertiary}{fg=gray!20!white, bg=NYUPurple}

\setbeamertemplate{headline}{}

\setbeamercolor{parttitle}{fg=NYUPurple}
\setbeamercolor{sectiontitle}{fg=NYUPurple}
\setbeamercolor{sectionname}{fg=NYUPurple}
\setbeamercolor{section page}{fg=NYUPurple}

\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
\setbeamercolor{section title}{fg=NYUPurple}
 \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
    \usebeamerfont{title}\usebeamercolor[fg]{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}
\end_preamble
\options aspectratio=169,handout
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "eulervm" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\pdf_quoted_options "allcolors=NYUPurple,urlcolor=LightPurple"
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 0
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\boxbgcolor #ff31d8
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\reals}{\mathbf{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\integers}{\mathbf{Z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\naturals}{\mathbf{N}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rationals}{\mathbf{Q}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ca}{\mathcal{A}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cb}{\mathcal{B}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cc}{\mathcal{C}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cd}{\mathcal{D}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ce}{\mathcal{E}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cf}{\mathcal{F}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cg}{\mathcal{G}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ch}{\mathcal{H}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ci}{\mathcal{I}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cj}{\mathcal{J}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ck}{\mathcal{K}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cl}{\mathcal{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cm}{\mathcal{M}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cn}{\mathcal{N}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\co}{\mathcal{O}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cp}{\mathcal{P}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cq}{\mathcal{Q}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\calr}{\mathcal{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cs}{\mathcal{S}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ct}{\mathcal{T}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cu}{\mathcal{U}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cv}{\mathcal{V}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cw}{\mathcal{W}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cx}{\mathcal{X}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cy}{\mathcal{Y}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cz}{\mathcal{Z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ind}[1]{1(#1)}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
pr}{P}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\pr}{\mathbb{P}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\predsp}{\cy}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%{
\backslash
hat{
\backslash
cy}}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\outsp}{\cy}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\prxy}{P_{\cx\times\cy}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\prx}{P_{\cx}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\prygivenx}{P_{\cy\mid\cx}}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
ex}{E}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\ex}{\mathbb{E}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\var}{\textrm{Var}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cov}{\textrm{Cov}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\sgn}{\textrm{sgn}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\sign}{\textrm{sign}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\kl}{\textrm{KL}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\law}{\mathcal{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\eps}{\varepsilon}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\as}{\textrm{ a.s.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\io}{\textrm{ i.o.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ev}{\textrm{ ev.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\convd}{\stackrel{d}{\to}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\eqd}{\stackrel{d}{=}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\del}{\nabla}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\loss}{\ell}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\risk}{R}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\emprisk}{\hat{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\lossfnl}{L}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\emplossfnl}{\hat{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\empminimizer}[1]{\hat{#1}^{*}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\minimizer}[1]{#1^{*}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\optimizer}[1]{#1^{*}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\etal}{\textrm{et. al.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\tr}{\operatorname{tr}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\trace}{\operatorname{trace}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\diag}{\text{diag}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rank}{\text{rank}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\linspan}{\text{span}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\spn}{\text{span}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\proj}{\text{Proj}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\argmax}{\operatornamewithlimits{arg\, max}}
{\text{argmax}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\argmin}{\operatornamewithlimits{arg\, min}}
{\text{argmin}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\bfx}{\mathbf{x}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfy}{\mathbf{y}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfl}{\mathbf{\lambda}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfm}{\mathbf{\mu}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\calL}{\mathcal{L}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\vw}{\boldsymbol{w}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vx}{\boldsymbol{x}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vxi}{\boldsymbol{\xi}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\valpha}{\boldsymbol{\alpha}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vbeta}{\boldsymbol{\beta}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vsigma}{\boldsymbol{\sigma}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vtheta}{\boldsymbol{\theta}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vd}{\boldsymbol{d}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vs}{\boldsymbol{s}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vt}{\boldsymbol{t}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vh}{\boldsymbol{h}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ve}{\boldsymbol{e}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vf}{\boldsymbol{f}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vg}{\boldsymbol{g}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vz}{\boldsymbol{z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vk}{\boldsymbol{k}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\va}{\boldsymbol{a}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vb}{\boldsymbol{b}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vv}{\boldsymbol{v}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vy}{\boldsymbol{y}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\dom}{\textrm{\textbf{dom} }}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\rank}{\text{\textbf{rank }}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\conv}{\textrm{\textbf{conv} }}
\end_inset


\begin_inset FormulaMacro
\newcommand{\relint}{\text{\textbf{relint }}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\aff}{\text{\textbf{aff }}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\hil}{\ch}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rkhs}{\hil}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ber}{\text{Ber}}
\end_inset


\end_layout

\begin_layout Title
Backpropagation and the Chain Rule
\begin_inset Argument 1
status open

\begin_layout Plain Layout
DS-GA 1003 / CSCI-GA 2567
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
optional, use only with long paper titles
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Author
David S.
 Rosenberg 
\end_layout

\begin_layout Date
April 17, 2018
\end_layout

\begin_layout Institute
New York University
\end_layout

\begin_layout Standard
\begin_inset Flex ArticleMode
status open

\begin_layout Plain Layout
Just in article version
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Todo: 1) why is backprop a good algorithm, compared to something else? (computat
ion reuse)
\end_layout

\begin_layout Plain Layout
2) what about running forward? the forward pass
\end_layout

\begin_layout Plain Layout
3) define a computation graph? (directed acyclic)
\end_layout

\begin_layout Plain Layout
minibatches; apply to a standard MLP;...
\end_layout

\begin_layout Plain Layout
4) In regularized ridge regression, emphasize that the computation graph
 is for the objective function, and highlight the subgraph that we would
 actually use for inference/prediction
\end_layout

\begin_layout Plain Layout
5) Add example of multi-layer perceptron?
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{Plots courtesy of Ningshan Zhang.}}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Contents
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\end_deeper
\begin_layout Section
Introduction
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Learning with Back-Propagation
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Itemize
Back-propagation is an 
\series bold
algorithm
\series default
 for computing the gradient
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
With lots of chain rule, you could also work out the gradient by hand.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Back-propagation is 
\end_layout

\begin_deeper
\begin_layout Itemize
a clean way to organize the computation of the gradient
\end_layout

\begin_layout Itemize
an efficient way to compute the gradient
\begin_inset Note Note
status open

\begin_layout Pause

\end_layout

\begin_layout Itemize
Nice introduction to this perspective:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset CommandInset href
LatexCommand href
name "Stanford CS221 Lecture 3 (2016), Slides 75-94"
target "http://web.stanford.edu/class/cs221/lectures/learning2.pdf#page=59"
literal "false"

\end_inset


\end_layout

\end_deeper
\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Partial Derivatives and the Chain Rule
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Partial Derivatives
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Consider a function 
\begin_inset Formula $g:\reals^{p}\to\reals^{n}$
\end_inset

.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.4
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Typical computation graph:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/one-fn-comp-graph.png
	lyxscale 20
	scale 7

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.4
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Broken out into components:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/one-fn-comp-graph-partials.png
	lyxscale 20
	scale 7

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Partial Derivatives
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Consider a function 
\begin_inset Formula $g:\reals^{p}\to\reals^{n}$
\end_inset

.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.35
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/one-fn-comp-graph-partials.png
	lyxscale 20
	scale 7

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.5
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Partial derivative 
\begin_inset Formula $\frac{\partial b_{i}}{\partial a_{j}}$
\end_inset

 is the instantaneous rate of change of 
\begin_inset Formula $b_{i}$
\end_inset

 as we change 
\begin_inset Formula $a_{j}$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Note Note
status open

\begin_layout Itemize
Imagine each of the 
\begin_inset Formula $a_{i}$
\end_inset

's has a slider that we can use to adjust the value.
\end_layout

\end_inset

If we change 
\begin_inset Formula $a_{j}$
\end_inset

 slightly to 
\begin_inset Formula $a_{j}+\delta$
\end_inset

,
\end_layout

\begin_layout Itemize
Then (for small 
\begin_inset Formula $\delta$
\end_inset

), 
\begin_inset Formula $b_{i}$
\end_inset

 changes to approximately 
\begin_inset Formula $b_{i}+\frac{\partial b_{i}}{\partial a_{j}}\delta$
\end_inset

.
\begin_inset Note Note
status open

\begin_layout Plain Layout
[The 
\begin_inset Formula $n\times p$
\end_inset

 matrix of partial derivatives 
\begin_inset Formula $J$
\end_inset

, with 
\begin_inset Formula $J_{ij}=\frac{\partial b_{i}}{\partial a_{j}}$
\end_inset

, is called the 
\series bold
Jacobian
\series default
 of 
\begin_inset Formula $g$
\end_inset

.]
\end_layout

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Partial Derivatives of an Affine Function
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Define the affine function 
\begin_inset Formula $g(x)=Mx+c$
\end_inset

, for 
\begin_inset Formula $M\in\reals^{n\times p}$
\end_inset

 and 
\begin_inset Formula $c\in\reals$
\end_inset

.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.35
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/one-fn-comp-graph-partials.png
	lyxscale 20
	scale 6.25

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.5
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
If we let 
\begin_inset Formula $b=g(a)$
\end_inset

, then what is 
\begin_inset Formula $b_{i}$
\end_inset

?
\end_layout

\begin_layout Itemize
\begin_inset Formula $b_{i}$
\end_inset

 depends on the 
\begin_inset Formula $i$
\end_inset

th row of 
\begin_inset Formula $M$
\end_inset

: 
\begin_inset Formula 
\[
b_{i}=\sum_{k=1}^{p}M_{ik}a_{k}+c_{i}
\]

\end_inset

and 
\begin_inset Formula 
\[
\frac{\partial b_{i}}{\partial a_{j}}=M_{ij}.
\]

\end_inset


\end_layout

\begin_layout Itemize
So for an an affine mapping, entries of matrix 
\begin_inset Formula $M$
\end_inset

 directly tell us the rates of change.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Chain Rule (in terms of partial derivatives)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $g:\reals^{p}\to\reals^{n}$
\end_inset

 and 
\begin_inset Formula $f:\reals^{n}\to\reals^{m}$
\end_inset

.
 Let 
\begin_inset Formula $b=g(a)$
\end_inset

.
 Let 
\begin_inset Formula $c=f(b)$
\end_inset

.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.5
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/two-fn-comp-graph-partials.png
	lyxscale 17
	width 100col%

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.4
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Itemize

\series bold
Chain rule
\series default
 says that
\begin_inset Formula 
\[
\frac{\partial c_{i}}{\partial a_{j}}=\sum_{k=1}^{n}\frac{\partial c_{i}}{\partial b_{k}}\frac{\partial b_{k}}{\partial a_{j}}.
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Change in 
\begin_inset Formula $a_{j}$
\end_inset

 may change each of 
\begin_inset Formula $b_{1},\ldots,b_{n}$
\end_inset

.
 
\end_layout

\begin_layout Itemize
Changes in 
\begin_inset Formula $b_{1},\ldots,b_{n}$
\end_inset

 may each effect 
\begin_inset Formula $c_{i}$
\end_inset

.
\end_layout

\begin_layout Itemize
Chain rule tells us that, to first order, the net change in 
\begin_inset Formula $c_{i}$
\end_inset

 is 
\end_layout

\begin_deeper
\begin_layout Itemize
the sum of the changes induced along each path from 
\begin_inset Formula $a_{j}$
\end_inset

 to 
\begin_inset Formula $c_{i}$
\end_inset

.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Example: Least Squares Regression
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Review: Linear least squares
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Hypothesis space 
\begin_inset Formula $\left\{ f(x)=w^{T}x+b\mid w\in\reals^{d},b\in\reals\right\} $
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Data set 
\begin_inset Formula $\left(x_{1},y_{1}\right),\ldots,\left(x_{n},y_{n}\right)\in\reals^{d}\times\reals$
\end_inset

.
\end_layout

\begin_layout Itemize
Define
\begin_inset Formula 
\[
\ell_{i}(w,b)=\left[\left(w^{T}x_{i}+b\right)-y_{i}\right]^{2}.
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
In SGD, in each round we'd choose a random index 
\begin_inset Formula $i\in1,\ldots,n$
\end_inset

 and take a gradient step
\begin_inset Formula 
\begin{eqnarray*}
w_{j} & \gets & w_{j}-\eta\frac{\partial\ell_{i}(w,b)}{\partial w_{j}}\text{, for }j=1,\ldots,d\\
b & \gets & b-\eta\frac{\partial\ell_{i}(w,b)}{\partial b},
\end{eqnarray*}

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Formula 
\begin{eqnarray*}
w & \gets & w-\eta\del_{w}\ell_{i}(w,b)\\
b & \gets & b-\eta\del_{b}\ell_{i}(w,b),
\end{eqnarray*}

\end_inset


\end_layout

\end_inset

for some step size 
\begin_inset Formula $\eta>0$
\end_inset

.
\end_layout

\begin_layout Itemize
Let's revisit how to calculate these partial derivatives...
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Computation Graph and Intermediate Variables
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
For a generic training point 
\begin_inset Formula $\left(x,y\right)$
\end_inset

, denote the loss by 
\begin_inset Formula 
\[
\ell(w,b)=\left[\left(w^{T}x+b\right)-y\right]^{2}.
\]

\end_inset


\end_layout

\begin_layout Itemize
Let's break this down into some intermediate computations:
\end_layout

\begin_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.35
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\text{(prediction) }\hat{y} & = & \sum_{j=1}^{d}w_{j}x_{j}+b\\
\pause\text{(residual) }r & = & y-\hat{y}\\
\pause\text{(loss) }\ell & = & r^{2}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.65
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/backpropagation/linear-sqr-loss-comp-graph-labels.png
	lyxscale 30
	height 45theight%

\end_inset


\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Partial Derivatives on Computation Graph
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
We'll work our way from graph output 
\begin_inset Formula $\ell$
\end_inset

 back to the parameters 
\begin_inset Formula $w$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout ColumnsCenterAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.45
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/linear-sqr-loss-comp-graph.png
	lyxscale 30
	width 100col%

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.45
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\frac{\partial\ell}{\partial r} & = & \pause2r\\
\frac{\partial\ell}{\partial\hat{y}} & = & \pause\frac{\partial\ell}{\partial r}\frac{\partial r}{\partial\hat{y}}=\left(2r\right)(-1)=-2r\\
\frac{\partial\ell}{\partial b} & = & \pause\frac{\partial\ell}{\partial\hat{y}}\frac{\partial\hat{y}}{\partial b}=\left(-2r\right)(1)=-2r\\
\frac{\partial\ell}{\partial w_{j}} & = & \pause\frac{\partial\ell}{\partial\hat{y}}\frac{\partial\hat{y}}{\partial w_{j}}=\left(-2r\right)x_{j}=-2rx_{j}
\end{eqnarray*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Section
Example: Ridge Regression
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Ridge Regression: Computation Graph and Intermediate Variables
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
For training point 
\begin_inset Formula $\left(x,y\right)$
\end_inset

, the 
\begin_inset Formula $\ell_{2}$
\end_inset

-regularized objective function is 
\begin_inset Formula 
\[
J(w,b)=\left[\left(w^{T}x+b\right)-y\right]^{2}+\lambda w^{T}w.
\]

\end_inset


\end_layout

\begin_layout Itemize
Let's break this down into some intermediate computations:
\end_layout

\begin_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.35
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\text{(prediction) }\hat{y} & = & \sum_{j=1}^{d}w_{j}x_{j}+b\\
\pause\text{(residual) }r & = & y-\hat{y}\\
\pause\text{(loss) }\ell & = & r^{2}\\
\pause\text{(regularization) }R & = & \lambda w^{T}w\\
\pause\text{(objective) }J & = & \ell+R
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.65
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/backpropagation/ridge-regression-comp-graph-labels.png
	lyxscale 30
	height 45theight%

\end_inset


\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Partial Derivatives on Computation Graph
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
We'll work our way from graph output 
\begin_inset Formula $\ell$
\end_inset

 back to the parameters 
\begin_inset Formula $w$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout ColumnsCenterAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.45
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/ridge-regression-comp-graph-labels.png
	lyxscale 30
	width 100col%

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.45
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\frac{\partial J}{\partial\ell} & = & \frac{\partial J}{\partial R}=\pause1\\
\frac{\partial J}{\partial\hat{y}} & = & \pause\frac{\partial J}{\partial\ell}\frac{\partial\ell}{\partial r}\frac{\partial r}{\partial\hat{y}}=\left(1\right)(2r)\left(-1\right)=-2r\\
\frac{\partial J}{\partial b} & = & \pause\frac{\partial J}{\partial\hat{y}}\frac{\partial\hat{y}}{\partial b}=\left(-2r\right)\left(1\right)=-2r\\
\frac{\partial J}{\partial w_{j}} & = & \text{?}
\end{eqnarray*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Handling Nodes with Multiple Children
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Consider 
\begin_inset Formula $a\mapsto J=h(f(a),g(a))$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/split-output.png
	lyxscale 40
	height 30theight%

\end_inset


\end_layout

\begin_layout Itemize
It's helpful to think about having two independent copies of 
\begin_inset Formula $a$
\end_inset

, call them 
\begin_inset Formula $a^{(1)}$
\end_inset

 and 
\begin_inset Formula $a^{(2)}$
\end_inset

...
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Handling Nodes with Multiple Children
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout ColumnsCenterAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.45
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/split-output-2copies.png
	lyxscale 30
	width 100col%

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.45
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\frac{\partial J}{\partial a} & = & \pause\frac{\partial J}{\partial a^{(1)}}\frac{\partial a^{(1)}}{\partial a}+\frac{\partial J}{\partial a^{(2)}}\frac{\partial a^{(2)}}{\partial a}\\
 & = & \pause\frac{\partial J}{\partial a^{(1)}}+\frac{\partial J}{\partial a^{(2)}}
\end{eqnarray*}

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Derivative w.r.t.
 
\begin_inset Formula $a$
\end_inset

 is the sum of derivatives w.r.t.
 each copy of 
\begin_inset Formula $a$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Partial Derivatives on Computation Graph
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
We'll work our way from graph output 
\begin_inset Formula $\ell$
\end_inset

 back to the parameters 
\begin_inset Formula $w$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout ColumnsCenterAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.45
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/ridge-regression-comp-graph-labels-2copies.png
	lyxscale 30
	width 100col%

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.45
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\frac{\partial J}{\partial\hat{y}} & = & \frac{\partial J}{\partial\ell}\frac{\partial\ell}{\partial r}\frac{\partial r}{\partial\hat{y}}=\left(1\right)(2r)\left(-1\right)=-2r\\
\frac{\partial J}{\partial w_{j}^{(2)}} & = & \pause\frac{\partial J}{\partial\hat{y}}\frac{\partial\hat{y}}{\partial w_{j}^{(2)}}=\frac{\partial J}{\partial\hat{y}}x_{j}\\
\frac{\partial J}{\partial w_{j}^{(1)}} & = & \pause\frac{\partial J}{\partial R}\frac{\partial R}{\partial w_{j}^{(1)}}=\left(1\right)\left(2\lambda w_{j}^{(1)}\right)\\
\frac{\partial J}{\partial w_{j}} & = & \pause\frac{\partial J}{\partial w_{j}^{(1)}}+\frac{\partial J}{\partial w_{j}^{(2)}}
\end{eqnarray*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Section
General Backpropagation
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Backpropagation: Overview
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Backpropagation is a specific way to evaluate the partial derivatives of
 a computation graph output 
\begin_inset Formula $J$
\end_inset

 w.r.t.
 the inputs and outputs of all nodes.
 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Backpropagation works node-by-node.
\end_layout

\begin_layout Itemize
To run a 
\begin_inset Quotes eld
\end_inset

backward
\begin_inset Quotes erd
\end_inset

 step at a node 
\begin_inset Formula $f$
\end_inset

, we assume
\end_layout

\begin_deeper
\begin_layout Itemize
we've already run 
\begin_inset Quotes eld
\end_inset

backward
\begin_inset Quotes erd
\end_inset

 for all of 
\begin_inset Formula $f$
\end_inset

's children.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Backward
\series default
 at node 
\begin_inset Formula $f:a\mapsto b$
\end_inset

 returns
\end_layout

\begin_deeper
\begin_layout Itemize
Partial of objective value 
\begin_inset Formula $J$
\end_inset

 w.r.t.
 
\begin_inset Formula $f$
\end_inset

's output: 
\begin_inset Formula $\frac{\partial J}{\partial b}$
\end_inset


\end_layout

\begin_layout Itemize
Partial of objective value 
\begin_inset Formula $J$
\end_inset

 w.r.t 
\begin_inset Formula $f$
\end_inset

's input: 
\begin_inset Formula $\frac{\partial J}{\partial a}$
\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Backpropagation: Simple Case
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Simple case: all nodes take a single scalar as input and have a single scalar
 output.
\end_layout

\begin_deeper
\begin_layout ColumnsCenterAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.45
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/backprop-general-node.png
	lyxscale 50
	width 100col%

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.5
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Backprop for node 
\begin_inset Formula $f$
\end_inset

:
\end_layout

\begin_layout Itemize

\series bold
Input
\series default
: 
\begin_inset Formula $\frac{\partial J}{\partial b^{(1)}},\ldots,\frac{\partial J}{\partial b^{(N)}}$
\end_inset

 
\begin_inset Newline newline
\end_inset

(Partials w.r.t.
 inputs to all children)
\end_layout

\begin_layout Itemize

\series bold
Output
\series default
: 
\begin_inset Formula 
\begin{eqnarray*}
\frac{\partial J}{\partial b} & = & \sum_{k=1}^{N}\frac{\partial J}{\partial b^{(k)}}\\
\text{ }\frac{\partial J}{\partial a} & = & \frac{\partial J}{\partial b}\frac{\partial b}{\partial a}
\end{eqnarray*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Backpropagation (General case)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
More generally, consider 
\begin_inset Formula $f:\reals^{d}\to\reals^{n}$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout ColumnsCenterAligned

\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.45
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../Figures/backpropagation/backprop-general-node.png
	lyxscale 50
	width 100col%

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.5
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Itemize

\series bold
Input
\series default
: 
\begin_inset Formula $\frac{\partial J}{\partial b_{j}^{(i)}}$
\end_inset

, 
\begin_inset Formula $i=1,\ldots,N$
\end_inset

, 
\begin_inset Formula $j=1,\ldots,n$
\end_inset


\end_layout

\begin_layout Itemize

\series bold
Output
\series default
: 
\begin_inset Formula 
\begin{eqnarray*}
\frac{\partial J}{\partial b_{j}} & = & \sum_{k=1}^{N}\frac{\partial J}{\partial b_{j}^{(k)}}\\
\frac{\partial J}{\partial a_{i}} & = & \sum_{j=1}^{n}\frac{\partial J}{\partial b_{j}}\frac{\partial b_{j}}{\partial a_{i}}
\end{eqnarray*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Running Backpropagation
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
If we run 
\begin_inset Quotes eld
\end_inset

backward
\begin_inset Quotes erd
\end_inset

 on every node in our graph,
\end_layout

\begin_deeper
\begin_layout Itemize
we'll have the gradients of 
\begin_inset Formula $J$
\end_inset

 w.r.t.
 all our parameters.
\end_layout

\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
To run backward on a particular node,
\end_layout

\begin_deeper
\begin_layout Itemize
we assumed we already ran it on all children.
\end_layout

\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
A 
\series bold
topological sort
\series default
 of the nodes in a directed [acyclic] graph
\end_layout

\begin_deeper
\begin_layout Itemize
is an ordering which every node appears before its children.
\end_layout

\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
So we'll evaluate backward on nodes in a 
\series bold
reverse topological ordering
\series default
.
\begin_inset Note Note
status collapsed

\begin_layout Section
Standard Multilayer Perceptron
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gradient of a Hidden Computation Node
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
For simplicity, consider the a hidden layer with a single node and tanh
 nonlinearity:
\begin_inset Formula 
\[
o(x)=\tanh(w^{T}x+b)
\]

\end_inset

for parameters 
\begin_inset Formula $b\in\reals$
\end_inset

 and 
\begin_inset Formula $w\in\reals^{d}$
\end_inset

.
 We can represent this in a computation graph as
\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../Figures/backpropagation/hidden-comp-node.png
	lyxscale 20
	height 30theight%

\end_inset


\end_layout

\begin_layout Itemize
The chain rule tells us that
\begin_inset Formula 
\begin{eqnarray*}
\frac{\partial o}{\partial b} & = & \frac{\partial o}{\partial a}\frac{\partial a}{\partial b}=\left(1-o^{2}\right)\\
\pause\frac{\partial o}{\partial w_{j}} & = & \frac{\partial o}{\partial a}\frac{\partial a}{\partial w_{j}}=\left(1-o^{2}\right)x_{j}\quad j=1,\ldots,d
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
Suppose we can write a first order approximation to 
\begin_inset Formula $o$
\end_inset

 as
\begin_inset Formula 
\[
o\approx g_{w}^{T}w+g_{b}b+c,
\]

\end_inset

where 
\begin_inset Formula $c,g_{b}\in\reals$
\end_inset

 and 
\begin_inset Formula $g_{w}\in\reals^{d}$
\end_inset

 may depend on 
\begin_inset Formula $x$
\end_inset

.
 
\end_layout

\begin_layout Itemize
Then the we know that 
\begin_inset Formula $g_{w}$
\end_inset

 and 
\begin_inset Formula $g_{b}$
\end_inset

 are the gradients of 
\begin_inset Formula $o$
\end_inset

 w.r.t.
 
\begin_inset Formula $w$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 respectively.
 
\end_layout

\end_deeper
\end_inset


\end_layout

\end_deeper
\end_body
\end_document
