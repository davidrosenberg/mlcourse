#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin /Users/drosen/Dropbox/repos/mlcourse/Lectures/
\textclass beamer
\begin_preamble
\usetheme{CambridgeUS} 
\beamertemplatenavigationsymbolsempty


\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
  \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
    \usebeamerfont{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}
\end_preamble
\options handout,aspectratio=169
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "eulervm" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 0
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\reals}{\mathbf{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\integers}{\mathbf{Z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\naturals}{\mathbf{N}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rationals}{\mathbf{Q}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ca}{\mathcal{A}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cb}{\mathcal{B}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cc}{\mathcal{C}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cd}{\mathcal{D}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ce}{\mathcal{E}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cf}{\mathcal{F}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cg}{\mathcal{G}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ch}{\mathcal{H}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ci}{\mathcal{I}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cj}{\mathcal{J}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ck}{\mathcal{K}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cl}{\mathcal{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cm}{\mathcal{M}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cn}{\mathcal{N}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\co}{\mathcal{O}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cp}{\mathcal{P}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cq}{\mathcal{Q}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\calr}{\mathcal{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cs}{\mathcal{S}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ct}{\mathcal{T}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cu}{\mathcal{U}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cv}{\mathcal{V}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cw}{\mathcal{W}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cx}{\mathcal{X}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cy}{\mathcal{Y}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cz}{\mathcal{Z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ind}[1]{1(#1)}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
pr}{P}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\pr}{\mathbb{P}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\predsp}{\cy}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%{
\backslash
hat{
\backslash
cy}}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\outsp}{\cy}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\prxy}{P_{\cx\times\cy}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\prx}{P_{\cx}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\prygivenx}{P_{\cy\mid\cx}}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
ex}{E}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\ex}{\mathbb{E}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\var}{\textrm{Var}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cov}{\textrm{Cov}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\sgn}{\textrm{sgn}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\sign}{\textrm{sign}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\kl}{\textrm{KL}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\law}{\mathcal{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\eps}{\varepsilon}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\as}{\textrm{ a.s.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\io}{\textrm{ i.o.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ev}{\textrm{ ev.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\convd}{\stackrel{d}{\to}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\eqd}{\stackrel{d}{=}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\del}{\nabla}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\loss}{\ell}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\risk}{R}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\emprisk}{\hat{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\lossfnl}{L}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\emplossfnl}{\hat{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\empminimizer}[1]{\hat{#1}^{*}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\minimizer}[1]{#1^{*}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\optimizer}[1]{#1^{*}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\etal}{\textrm{et. al.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\tr}{\operatorname{tr}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\trace}{\operatorname{trace}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\diag}{\text{diag}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rank}{\text{rank}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\linspan}{\text{span}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\spn}{\text{span}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\proj}{\text{Proj}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\argmax}{\operatornamewithlimits{arg\, max}}
{\text{argmax}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\argmin}{\operatornamewithlimits{arg\, min}}
{\text{argmin}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\bfx}{\mathbf{x}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfy}{\mathbf{y}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfl}{\mathbf{\lambda}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfm}{\mathbf{\mu}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\calL}{\mathcal{L}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\vw}{\boldsymbol{w}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vx}{\boldsymbol{x}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vxi}{\boldsymbol{\xi}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\valpha}{\boldsymbol{\alpha}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vbeta}{\boldsymbol{\beta}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vsigma}{\boldsymbol{\sigma}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vtheta}{\boldsymbol{\theta}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vd}{\boldsymbol{d}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vs}{\boldsymbol{s}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vt}{\boldsymbol{t}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vh}{\boldsymbol{h}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ve}{\boldsymbol{e}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vf}{\boldsymbol{f}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vg}{\boldsymbol{g}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vz}{\boldsymbol{z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vk}{\boldsymbol{k}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\va}{\boldsymbol{a}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vb}{\boldsymbol{b}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vv}{\boldsymbol{v}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vy}{\boldsymbol{y}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\dom}{\textrm{\textbf{dom} }}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\rank}{\text{\textbf{rank }}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\conv}{\textrm{\textbf{conv} }}
\end_inset


\begin_inset FormulaMacro
\newcommand{\relint}{\text{\textbf{relint }}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\aff}{\text{\textbf{aff }}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\hil}{\ch}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rkhs}{\hil}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ber}{\text{Ber}}
\end_inset


\end_layout

\begin_layout Title
Introduction to Kernel Methods
\begin_inset Argument 1
status open

\begin_layout Plain Layout
DS-GA 1003 
\begin_inset Note Note
status open

\begin_layout Plain Layout
optional, use only with long paper titles
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Author
David Rosenberg 
\end_layout

\begin_layout Date
February 21, 2017
\end_layout

\begin_layout Institute
New York University
\end_layout

\begin_layout Standard
\begin_inset Flex ArticleMode
status open

\begin_layout Plain Layout
Just in article version
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{Plots courtesy of Ningshan Zhang.}}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Section
Setup and Motivation
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
The Input Space 
\begin_inset Formula $\cx$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Our general learning theory setup: no assumptions about 
\begin_inset Formula $\cx$
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
But 
\begin_inset Formula $\cx=\reals^{d}$
\end_inset

 for the specific methods we've developed: 
\end_layout

\begin_deeper
\begin_layout Itemize
Ridge regression
\end_layout

\begin_layout Itemize
Lasso regression
\end_layout

\begin_layout Itemize
Support Vector Machines
\end_layout

\begin_layout Itemize
Perceptrons
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Our hypothesis space for these was all affine functions on 
\begin_inset Formula $\reals^{d}$
\end_inset

:
\begin_inset Formula 
\[
\ch=\left\{ x\mapsto w^{T}x+b\mid w\in\reals^{d},b\in\reals\right\} .
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
What if we want to do prediction on inputs not natively in 
\begin_inset Formula $\reals^{d}$
\end_inset

?
\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Feature Extraction
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Definition
Mapping an input from 
\begin_inset Formula $\cx$
\end_inset

 to a vector in 
\begin_inset Formula $\reals^{d}$
\end_inset

 is called 
\series bold
feature extraction
\series default
 or 
\series bold
featurization
\series default
.
 
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Archive/2015/Lectures/source/4a.kernels-highlevel/feature-extraction.png
	lyxscale 60
	width 90text%

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Archive/2015/Lectures/source/4a.kernels-highlevel/feature-extraction.png
	width 80text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
e.g.
 Quadratic feature map: 
\begin_inset Formula $\cx=\reals^{d}$
\end_inset


\begin_inset Formula 
\[
\ensuremath{\phi(x)=(x_{1},\ldots,x_{d},x_{1}^{2},\ldots,x_{d}^{2},\sqrt{2}x_{1}x_{2},\ldots,\sqrt{2}x_{i}x_{j},\ldots\sqrt{2}x_{d-1}x_{d})^{T}}.
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Linear Models with Explicit Feature Map
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Rather than take 
\begin_inset Formula $\cx=\reals^{d}$
\end_inset

, let 
\begin_inset Formula $\cx$
\end_inset

 be its own thing:
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Input space: 
\begin_inset Formula $\cx$
\end_inset

 
\end_layout

\begin_layout Itemize
Introduce 
\series bold
feature map
\series default
 
\begin_inset Formula $\psi:\cx\to\reals^{d}$
\end_inset


\end_layout

\begin_layout Itemize
The feature map maps into the 
\series bold
feature space
\series default
 
\begin_inset Formula $\reals^{d}$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Hypothesis space of affine functions on feature space:
\begin_inset Formula 
\[
\ch=\left\{ x\mapsto w^{T}\psi(x)+b\mid w\in\reals^{d},b\in\reals\right\} .
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Linear Models Need Big Feature Spaces
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
To get 
\series bold
expressive
\series default
 hypothesis spaces using linear models, 
\end_layout

\begin_deeper
\begin_layout Itemize
need high-dimensional feature spaces
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
(What do we mean by expressive?)
\end_layout

\end_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
Very large feature spaces have two problems:
\end_layout

\begin_deeper
\begin_layout Enumerate
Overfitting
\end_layout

\begin_layout Enumerate
Memory and computational costs 
\end_layout

\end_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
Overfitting we handle with regularization.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Kernel methods can (sometimes) help with memory and computational costs.
\begin_inset Note Note
status open

\begin_layout Pause

\end_layout

\begin_layout Itemize
In practice, kernel methods most applicable for linear methods with 
\begin_inset Formula $\ell_{2}$
\end_inset

 regularization.
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Some Methods Can Be 
\begin_inset Quotes eld
\end_inset

Kernelized
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Definition
A method is 
\series bold
kernelized 
\series default
if inputs only appear inside inner products: 
\begin_inset Formula $\left\langle \psi(x),\psi(y)\right\rangle $
\end_inset

 for 
\begin_inset Formula $x,y\in\cx$
\end_inset

.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
The 
\series bold
kernel function
\series default
 corresponding to 
\begin_inset Formula $\psi$
\end_inset

 and inner product 
\begin_inset Formula $\left\langle \cdot,\cdot\right\rangle $
\end_inset

 is 
\begin_inset Formula 
\[
k(x,y)=\left\langle \psi(x),\psi(y)\right\rangle .
\]

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Why introduce this new notation 
\begin_inset Formula $k(x,y)$
\end_inset

?
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Turns out, we can often evaluate 
\begin_inset Formula $k(x,y)$
\end_inset

 directly,
\end_layout

\begin_deeper
\begin_layout Itemize
without explicilty computing 
\begin_inset Formula $\psi(x)$
\end_inset

 and 
\begin_inset Formula $\psi(y)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
For large feature spaces, can be much faster.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Kernel Evaluation Can Be Fast
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Example
Quadratic feature map
\begin_inset Formula 
\[
\ensuremath{\phi(x)=(x_{1},\ldots,x_{d},x_{1}^{2},\ldots,x_{d}^{2},\sqrt{2}x_{1}x_{2},\ldots,\sqrt{2}x_{i}x_{j},\ldots\sqrt{2}x_{d-1}x_{d})^{T}}
\]

\end_inset

has dimension 
\begin_inset Formula $O(d^{2})$
\end_inset

, but
\begin_inset Formula 
\[
k(w,x)=\left\langle \phi(w),\phi(x)\right\rangle =\left\langle w,x\right\rangle +\left\langle w,x\right\rangle ^{2}
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Naively explicit computation of 
\begin_inset Formula $k(w,x)$
\end_inset

: 
\begin_inset Formula $O(d^{2})$
\end_inset


\end_layout

\begin_layout Itemize
Implicit computation of 
\begin_inset Formula $k(w,x)$
\end_inset

: 
\begin_inset Formula $O(d)$
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Kernels as Similarity Scores
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Can think of the kernel function as a 
\series bold
similarity score
\series default
.
\end_layout

\begin_layout Itemize
But this is not precise.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
There are many ways to design a similarity score.
 
\end_layout

\begin_deeper
\begin_layout Itemize
A kernel function is special because it's an inner product.
\end_layout

\begin_layout Itemize
Has many mathematical benefits.
 
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
What's the Benefit of Kernelization?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Computational (e.g.
 when feature space dimension 
\begin_inset Formula $d$
\end_inset

 larger than sample size 
\begin_inset Formula $n$
\end_inset

).
 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
Access to infinite-dimensional feature spaces.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
Allows thinking in terms of 
\begin_inset Quotes eld
\end_inset

similarity
\begin_inset Quotes erd
\end_inset

 rather than features.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
(debatable)
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Section
Example: SVM 
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
SVM Dual
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Recall the SVM dual optimization problem
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\sup_{\alpha} &  & \sum_{i=1}^{n}\alpha_{i}-\frac{1}{2}\sum_{i,j=1}^{n}\alpha_{i}\alpha_{j}y_{i}y_{j}x_{j}^{T}x_{i}\\
\mbox{s.t.} &  & \sum_{i=1}^{n}\alpha_{i}y_{i}=0\\
 & \quad & \alpha_{i}\in\left[0,\frac{c}{n}\right]\;i=1,\ldots,n.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Notice: 
\begin_inset Formula $x$
\end_inset

's only show up as inner products with other 
\begin_inset Formula $x$
\end_inset

's.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Can replace 
\begin_inset Formula $x_{j}^{T}x_{i}$
\end_inset

 by an arbitrary kernel 
\begin_inset Formula $k(x_{j},x_{i})$
\end_inset

.
 
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
What kernel are we currently using?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
The Kernel Matrix (or the Gram Matrix)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Definition
For a set of 
\begin_inset Formula $\left\{ x_{1},\ldots,x_{n}\right\} $
\end_inset

 and an inner product 
\begin_inset Formula $\left\langle \cdot,\cdot\right\rangle $
\end_inset

 on the set, the 
\series bold
kernel matrix
\series default
 or the 
\series bold
Gram matrix
\series default
 is defined as
\begin_inset Formula 
\[
K=\begin{pmatrix}\left\langle x_{i},x_{j}\right\rangle \end{pmatrix}_{i,j}=\begin{pmatrix}\left\langle x_{1},x_{1}\right\rangle  & \cdots & \left\langle x_{1},x_{n}\right\rangle \\
\vdots & \ddots & \cdots\\
\left\langle x_{n},x_{1}\right\rangle  & \cdots & \left\langle x_{n},x_{n}\right\rangle 
\end{pmatrix}.
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Standard
Then for the standard Euclidean inner product 
\begin_inset Formula $\left\langle x_{i},x_{j}\right\rangle =x_{i}^{T}x_{j}$
\end_inset

, we have
\begin_inset Formula 
\[
K=XX^{T}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
SVM Dual with Kernel Matrix
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\sup_{\alpha} &  & \sum_{i=1}^{n}\alpha_{i}-\frac{1}{2}\sum_{i,j=1}^{n}\alpha_{i}\alpha_{j}y_{i}y_{j}K_{ji}\\
\mbox{s.t.} &  & \sum_{i=1}^{n}\alpha_{i}y_{i}=0\\
 & \quad & \alpha_{i}\in\left[0,\frac{c}{n}\right]\;i=1,\ldots,n.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
Once our algorithm works with kernel matrices, we can change kernel just
 by changing the matrix.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Size of matrix: 
\begin_inset Formula $n\times n$
\end_inset

, where 
\begin_inset Formula $n$
\end_inset

 is the number of data points.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Recall with ridge regression, we worked with 
\begin_inset Formula $X^{T}X$
\end_inset

, which is 
\begin_inset Formula $d\times d$
\end_inset

, where 
\begin_inset Formula $d$
\end_inset

 is feature space dimension.
\end_layout

\end_deeper
\begin_layout Section
Some Kernels
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Linear Kernel
\end_layout

\end_inset

 
\end_layout

\begin_deeper
\begin_layout Itemize
Input space: 
\begin_inset Formula $\cx=\reals^{d}$
\end_inset


\end_layout

\begin_layout Itemize
Feature space: 
\begin_inset Formula $\ch=\reals^{d}$
\end_inset

, with standard inner product
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Feature map
\begin_inset Formula 
\[
\psi(x)=x.
\]

\end_inset


\end_layout

\begin_layout Itemize
Kernel: 
\begin_inset Formula 
\[
k(w,x)=w^{T}x
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Quadratic Kernel in 
\begin_inset Formula $\reals^{2}$
\end_inset


\end_layout

\end_inset

 
\end_layout

\begin_deeper
\begin_layout Itemize
Input space: 
\begin_inset Formula $\cx=\reals^{2}$
\end_inset


\end_layout

\begin_layout Itemize
Feature space: 
\begin_inset Formula $\ch=\reals^{5}$
\end_inset


\end_layout

\begin_layout Itemize
Feature map:
\begin_inset Formula 
\[
\psi:(x_{1},x_{2})\mapsto\left(x_{1},x_{2},x_{1}^{2},x_{2}^{2},\sqrt{2}x_{1}x_{2}\right)
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Gives us ability to represent conic section boundaries.
 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Define kernel as inner product in feature space:
\begin_inset Formula 
\begin{eqnarray*}
k(w,x) & = & \langle\psi(w),\psi(x)\rangle\\
\pause & = & w_{1}x_{1}+w_{2}x_{2}+w_{1}^{2}x_{1}^{2}+w_{2}^{2}x_{2}^{2}+2w_{1}w_{2}x_{1}x_{2}\\
\pause & = & w_{1}x_{1}+w_{2}x_{2}+(w_{1}x_{1})^{2}+(w_{2}x_{2})^{2}+2(w_{1}x_{1})(w_{2}x_{2})\\
\pause & = & \langle w,x\rangle+\langle w,x\rangle^{2}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{Based on Guillaume Obozinski's Statistical Machine Learning course
 at Louvain, Feb 2014.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Quadratic Kernel in 
\begin_inset Formula $\reals^{d}$
\end_inset


\end_layout

\end_inset

 
\end_layout

\begin_deeper
\begin_layout Itemize
Input space 
\begin_inset Formula $\cx=\reals^{d}$
\end_inset


\end_layout

\begin_layout Itemize
Feature space: 
\begin_inset Formula $\ch=\reals^{D}$
\end_inset

, where 
\begin_inset Formula $D=d+{d \choose 2}\approx d^{2}/2$
\end_inset

.
\end_layout

\begin_layout Itemize
Feature map:
\begin_inset Formula 
\[
\ensuremath{\phi(x)=(x_{1},\ldots,x_{d},x_{1}^{2},\ldots,x_{d}^{2},\sqrt{2}x_{1}x_{2},\ldots,\sqrt{2}x_{i}x_{j},\ldots\sqrt{2}x_{d-1}x_{d})^{T}}
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Still have
\begin_inset Formula 
\begin{eqnarray*}
k(w,x) & = & \left\langle \phi(w),\phi(x)\right\rangle \\
\pause & = & \left\langle x,y\right\rangle +\left\langle x,y\right\rangle ^{2}
\end{eqnarray*}

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Computation for inner product with explicit mapping: 
\begin_inset Formula $O(d^{2})$
\end_inset


\end_layout

\begin_layout Itemize
Computation for implicit kernel calculation: 
\begin_inset Formula $O(d)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{Based on Guillaume Obozinski's Statistical Machine Learning course
 at Louvain, Feb 2014.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
String Kernel
\end_layout

\end_inset

 
\end_layout

\begin_deeper
\begin_layout Itemize
Computer virus finding: want to find a sequence of characters 
\begin_inset Formula $v$
\end_inset

 in a file that indicates file contains a virus.
\end_layout

\begin_layout Itemize
Alphabet set 
\begin_inset Formula $\Sigma$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\cx$
\end_inset

 is set of all finite-length strings over 
\begin_inset Formula $\Sigma$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\cx_{d}$
\end_inset

 is set of strings over 
\begin_inset Formula $\Sigma$
\end_inset

 of length at most 
\begin_inset Formula $d$
\end_inset

.
\end_layout

\begin_layout Itemize
Feature map - indiciator variable for every substring of length at most
 
\begin_inset Formula $d$
\end_inset

.
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Polynomial Kernel in 
\begin_inset Formula $\reals^{d}$
\end_inset


\end_layout

\end_inset

 
\end_layout

\begin_deeper
\begin_layout Itemize
Input space 
\begin_inset Formula $\cx=\reals^{d}$
\end_inset


\end_layout

\begin_layout Itemize
Kernel function:
\begin_inset Formula 
\[
k(w,x)=\left(1+\left\langle w,x\right\rangle \right)^{M}
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Corresponds to a feature map with all terms up to degree 
\begin_inset Formula $M$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
For any 
\begin_inset Formula $M$
\end_inset

, computing the kernel has same computational cost
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Cost of explicit inner product computation grows rapidly in 
\begin_inset Formula $M$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Radial Basis Function (RBF) / Gaussian Kernel
\end_layout

\end_inset

 
\end_layout

\begin_deeper
\begin_layout Itemize
Input space 
\begin_inset Formula $\cx=\reals^{d}$
\end_inset


\begin_inset Formula 
\[
k(w,x)=\exp\left(-\frac{\|w-x\|^{2}}{2\sigma^{2}}\right),
\]

\end_inset

where 
\begin_inset Formula $\sigma^{2}$
\end_inset

 is known as the bandwidth parameter.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Does it act like a similarity score?
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Why 
\begin_inset Quotes eld
\end_inset

radial
\begin_inset Quotes erd
\end_inset

?
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Have we departed from our 
\begin_inset Quotes eld
\end_inset

inner product of feature vector
\begin_inset Quotes erd
\end_inset

 recipe?
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
Yes and no: corresponds to an infinite dimensional feature vector
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Probably the most common nonlinear kernel.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Kernel Trick: Overview
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Recap
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Given a kernelized ML algorithm.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
Can swap out the inner product for a new kernel function.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
New kernel may correspond to a high dimensional feature space.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
Once kernel matrix is computed, computational cost depends on number of
 data points, rather than the dimension of feature space.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Standard
Swapping out a linear kernel for a new kernel is called the 
\series bold
kernel trick
\series default
.
\end_layout

\end_deeper
\begin_layout Standard

\end_layout

\end_body
\end_document
