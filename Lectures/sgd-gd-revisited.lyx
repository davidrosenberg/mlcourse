#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass beamer
\begin_preamble
\usetheme{CambridgeUS} 
\beamertemplatenavigationsymbolsempty


\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
  \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
    \usebeamerfont{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}
\end_preamble
\options handout
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "eulervm" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 0
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\reals}{\mathbf{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\integers}{\mathbf{Z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\naturals}{\mathbf{N}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rationals}{\mathbf{Q}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ca}{\mathcal{A}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cb}{\mathcal{B}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cc}{\mathcal{C}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cd}{\mathcal{D}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ce}{\mathcal{E}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cf}{\mathcal{F}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cg}{\mathcal{G}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ch}{\mathcal{H}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ci}{\mathcal{I}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cj}{\mathcal{J}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ck}{\mathcal{K}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cl}{\mathcal{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cm}{\mathcal{M}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cn}{\mathcal{N}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\co}{\mathcal{O}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cp}{\mathcal{P}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cq}{\mathcal{Q}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\calr}{\mathcal{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cs}{\mathcal{S}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ct}{\mathcal{T}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cu}{\mathcal{U}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cv}{\mathcal{V}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cw}{\mathcal{W}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cx}{\mathcal{X}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cy}{\mathcal{Y}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cz}{\mathcal{Z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ind}[1]{1(#1)}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
pr}{P}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\pr}{\mathbb{P}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\predsp}{\cy}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%{
\backslash
hat{
\backslash
cy}}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\outsp}{\cy}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\prxy}{P_{\cx\times\cy}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\prx}{P_{\cx}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\prygivenx}{P_{\cy\mid\cx}}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
ex}{E}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\ex}{\mathbb{E}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\var}{\textrm{Var}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cov}{\textrm{Cov}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\sgn}{\textrm{sgn}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\sign}{\textrm{sign}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\kl}{\textrm{KL}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\law}{\mathcal{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\eps}{\varepsilon}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\as}{\textrm{ a.s.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\io}{\textrm{ i.o.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ev}{\textrm{ ev.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\convd}{\stackrel{d}{\to}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\eqd}{\stackrel{d}{=}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\del}{\nabla}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\loss}{\ell}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\risk}{R}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\emprisk}{\hat{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\lossfnl}{L}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\emplossfnl}{\hat{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\empminimizer}[1]{\hat{#1}^{*}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\minimizer}[1]{#1^{*}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\optimizer}[1]{#1^{*}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\etal}{\textrm{et. al.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\tr}{\operatorname{tr}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\trace}{\operatorname{trace}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\diag}{\text{diag}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rank}{\text{rank}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\linspan}{\text{span}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\spn}{\text{span}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\proj}{\text{Proj}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\argmax}{\operatornamewithlimits{arg\, max}}
{\text{argmax}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\argmin}{\operatornamewithlimits{arg\, min}}
{\text{argmin}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\bfx}{\mathbf{x}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfy}{\mathbf{y}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfl}{\mathbf{\lambda}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfm}{\mathbf{\mu}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\calL}{\mathcal{L}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\vw}{\boldsymbol{w}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vx}{\boldsymbol{x}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vxi}{\boldsymbol{\xi}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\valpha}{\boldsymbol{\alpha}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vbeta}{\boldsymbol{\beta}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vsigma}{\boldsymbol{\sigma}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vtheta}{\boldsymbol{\theta}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vd}{\boldsymbol{d}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vs}{\boldsymbol{s}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vt}{\boldsymbol{t}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vh}{\boldsymbol{h}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ve}{\boldsymbol{e}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vf}{\boldsymbol{f}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vg}{\boldsymbol{g}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vz}{\boldsymbol{z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vk}{\boldsymbol{k}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\va}{\boldsymbol{a}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vb}{\boldsymbol{b}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vv}{\boldsymbol{v}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vy}{\boldsymbol{y}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\dom}{\textrm{\textbf{dom} }}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\rank}{\text{\textbf{rank }}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\conv}{\textrm{\textbf{conv} }}
\end_inset


\begin_inset FormulaMacro
\newcommand{\relint}{\text{\textbf{relint }}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\aff}{\text{\textbf{aff }}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\hil}{\ch}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rkhs}{\hil}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ber}{\text{Ber}}
\end_inset


\end_layout

\begin_layout Title
SGD and GD Revisited 
\begin_inset Argument 1
status open

\begin_layout Plain Layout
DS-GA 1003 
\begin_inset Note Note
status open

\begin_layout Plain Layout
optional, use only with long paper titles
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Author
David Rosenberg 
\end_layout

\begin_layout Date
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
today
\end_layout

\end_inset


\end_layout

\begin_layout Institute
New York University
\end_layout

\begin_layout Standard
\begin_inset Flex ArticleMode
status open

\begin_layout Plain Layout
Just in article version
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{Plots courtesy of Ningshan Zhang.}}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Need to give rate of SGD for strongly convex functions (It's 
\begin_inset Formula $O(1/\eps)$
\end_inset

 – see Nemirovsky et al '09, which is exponentially more steps than for
 GD...
 but then, does it really make a difference to this extent? NO - rest is
 explained in these slides...
 Just need that missing rate.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Terminology
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Iterative Optimization Methods
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Iterative Optimization (Generic Version)
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Pick some starting point 
\begin_inset Formula $x^{(0)}\in\reals^{d}$
\end_inset

.
\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $k=0,1,\ldots$
\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Choose a 
\series bold
step
\series default
 or 
\series bold
search direction 
\begin_inset Formula $v^{(k)}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Choose a 
\series bold
step size
\series default
 
\begin_inset Formula $t^{(k)}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Set 
\begin_inset Formula $x^{(k+1)}=x^{(k)}+t^{(k)}v^{(k)}$
\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
Despite the names,
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $v^{(k)}$
\end_inset

 is 
\series bold
not
\series default
 generally a unit vector.
\end_layout

\begin_layout Itemize
\begin_inset Formula $t^{(k)}$
\end_inset

 is 
\series bold
not
\series default
 
\begin_inset Formula $\|x^{(k+1)}-x^{(k)}\|$
\end_inset

 (unless 
\begin_inset Formula $\|v^{(k)}\|=1$
\end_inset

).
\end_layout

\end_deeper
\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Descent Directions
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Definition
A 
\series bold
[one-sided] directional derivative
\series default
 of 
\begin_inset Formula $f$
\end_inset

 at 
\begin_inset Formula $x$
\end_inset

 in the direction 
\begin_inset Formula $v$
\end_inset

 is
\begin_inset Formula 
\[
f'(x;v)=\lim_{h\downarrow0}\frac{f(x+hv)-f(x)}{h}.
\]

\end_inset

[Note: Can be 
\begin_inset Formula $\pm\infty$
\end_inset

, e.g.
 for discontinuous functions.]
\end_layout

\begin_layout Definition

\end_layout

\begin_layout Pause

\end_layout

\begin_layout Definition
\begin_inset Formula $v$
\end_inset

 is a 
\series bold
descent direction 
\series default
for 
\begin_inset Formula $f$
\end_inset

 at 
\begin_inset Formula $x$
\end_inset

 if 
\begin_inset Formula $f'(x;v)<0$
\end_inset

.
 
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Descent Directions
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
If 
\begin_inset Formula $f$
\end_inset

 is differentiable, then 
\begin_inset Formula 
\[
f'(x,v)=\del f(x)^{T}v.
\]

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
So if 
\begin_inset Formula $f$
\end_inset

 is differentiable, then 
\begin_inset Formula $v$
\end_inset

 is a descent direction at 
\begin_inset Formula $x$
\end_inset

 iff
\begin_inset Formula 
\[
\del f(x)^{T}v<0.
\]

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Newton 
\series default
step is a descent direction for strictly convex functions:
\begin_inset Formula 
\[
v_{\mbox{newton}}=-\left[\del^{2}f(x)\right]^{-1}\del f(x)
\]

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
Much faster convergence close to the optimum.
 
\end_layout

\begin_layout Itemize
Computing/storing inverse Hessian is too much in high dimensions.
\end_layout

\begin_layout Itemize
Quasi-Newton methods approximate Newton step, without Hessian (e.g.
 L-BFGS).
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Descent Method
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Definition
An iterative optimization method is a 
\series bold
descent method 
\series default
if every step is a descent direction.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Equivalently, we have a descent method if
\begin_inset Formula 
\[
f(x^{(k+1)})<f(x^{(k)}),
\]

\end_inset

except when 
\begin_inset Formula $x^{(k)}$
\end_inset

 is optimal.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Is SGD a descent method?
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Itemize
Is a negative subgradient a descent direction?
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Can we just follow a negative sub-gradient?
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Pause

\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $f$
\end_inset

 is convex and finite near 
\begin_inset Formula $x$
\end_inset

, then 
\begin_inset Formula $f'(x;v)$
\end_inset

 exists.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset Formula $f$
\end_inset

 is differentiable at 
\begin_inset Formula $x$
\end_inset

 iff for some 
\begin_inset Formula $g$
\end_inset

 and all 
\begin_inset Formula $v$
\end_inset

, 
\begin_inset Formula 
\[
f'(x;v)=g^{T}v.
\]

\end_inset

(And of course if such a 
\begin_inset Formula $g$
\end_inset

 exists, then 
\begin_inset Formula $g=\del f(x)$
\end_inset

.)
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Section
Stochastic Gradient Descent
\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gradient Descent
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Gradient Descent
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Initialize 
\begin_inset Formula $x=0$
\end_inset


\end_layout

\begin_layout Itemize
repeat
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $x\gets x-\eta\del f(x)$
\end_inset


\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
\begin_inset Quotes eld
\end_inset

Noisy
\begin_inset Quotes erd
\end_inset

 Gradient Descent 
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
\begin_inset Quotes eld
\end_inset

Noisy
\begin_inset Quotes erd
\end_inset

 Gradient Descent (not a standard name)
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Initialize 
\begin_inset Formula $x=0$
\end_inset


\end_layout

\begin_layout Itemize
repeat
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $x\gets x-\eta v$
\end_inset

 
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
Where 
\begin_inset Formula $\nu$
\end_inset

 is some estimate of 
\begin_inset Formula $\del f(x)$
\end_inset


\end_layout

\begin_layout Itemize
In minibatch SGD, we have 
\begin_inset Formula $\ex v=\del f(x)$
\end_inset

.
 (if sampling with replacement)
\end_layout

\begin_layout Itemize
With large batches, we get better estimates.
 ( 
\begin_inset Formula $\var\left(v\right)$
\end_inset

 decreases.)
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
SGD on Regularized Empirical Risk 
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Our typical objective function is of the form
\begin_inset Formula 
\begin{eqnarray*}
J(w) & = & \lambda\Omega(w)+\frac{1}{n}\sum_{i=1}^{n}\ell(f_{w}(x_{i}),y_{i})\\
\pause & = & \frac{1}{n}\sum_{i=1}^{n}h_{i}(w)
\end{eqnarray*}

\end_inset

where
\begin_inset Formula 
\begin{eqnarray*}
h_{i}(w) & = & \lambda\Omega(w)+\ell(f_{w}(x_{i}),y_{i}).
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
SGD on 
\begin_inset Formula $J(w)$
\end_inset

:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Choose 
\begin_inset Formula $i\in\left\{ 1,\ldots,n\right\} $
\end_inset

 uniformly at random
\end_layout

\begin_layout Itemize
Approximate approximate 
\begin_inset Formula $\del J(w)$
\end_inset

 by 
\begin_inset Formula $\del h_{i}(w)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
Step is unbiased for gradient:
\begin_inset Formula 
\[
\ex_{i\sim\text{Unif}(1,\ldots,n)}\del h_{i}(w)=\del J(w)
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
SGD on Risk
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Suppose 
\begin_inset Formula $\left(x,y\right)\sim P_{\cx\times\cy}$
\end_inset

 and objective is the expected loss:
\begin_inset Formula 
\begin{eqnarray*}
J(w) & = & \ex\ell(f_{w}(x),y).
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
SGD on 
\begin_inset Formula $J(w)$
\end_inset

:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Choose 
\begin_inset Formula $\left(x,y\right)\sim P_{\cx\times\cy}$
\end_inset

.
\end_layout

\begin_layout Itemize
Approximate 
\begin_inset Formula $\del_{w}J(w)$
\end_inset

 by 
\begin_inset Formula $\del_{w}\ell(f_{w}(x),y)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
Step is unbiased for gradient:
\begin_inset Formula 
\[
\ex_{\left(x,y\right)\sim P_{\cx\times\cy}}\del_{w}\ell(f_{w}(x),y)=\del_{w}\ex\ell(f_{w}(x),y)
\]

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
To implement this, need fresh samples from 
\begin_inset Formula $P_{\cx\times\cy}$
\end_inset

.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
If we're resampling from training set, 
\begin_inset Formula $\left(x,y\right)\sim\hat{P}_{\cx\times\cy}$
\end_inset

 we get back SGD.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{
\backslash
url{http://planetmath.org/differentiationundertheintegralsign}.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Section
Convergence Rates
\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Does SGD Catch Up to GD?
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Loss on ridge regression for GD and SGD with various stepsizes
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/optimization-rates/batch-vs-sgd-on-ridge-regression.png
	lyxscale 60
	height 60theight%

\end_inset


\end_layout

\begin_layout Itemize
Why doesn't SGD catch up to batch GD?
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Short answer: It does, just takes a very long time.
\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Convergence Rates for Gradient Descent
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
Assume 
\begin_inset Formula $f:\reals^{n}\to\reals$
\end_inset

 is convex and differentiable, and
\end_layout

\begin_layout Itemize
\begin_inset Formula $\del f$
\end_inset

 is 
\series bold
Lipschitz continuous
\series default
 with constant 
\begin_inset Formula $L>0$
\end_inset

, that is:
\begin_inset Formula 
\[
\|\del f(x)-\del f(y)\|\le L\|x-y\|\mbox{ for all }x,y
\]

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Theorem
Gradient descent with fixed step size 
\begin_inset Formula $t\le1/L$
\end_inset

 satisfies
\begin_inset Formula 
\[
f(x^{(k)})-f(x^{*})\le\frac{\|x^{(0)}-x^{*}\|^{2}}{2tk}.
\]

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
So GD has convergence rate 
\begin_inset Formula $O(1/k)$
\end_inset

.
 
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
To get 
\begin_inset Formula $f(x^{(k)})-f(x^{*})\le\eps$
\end_inset

, need 
\begin_inset Formula $O(1/\eps)$
\end_inset

 iterations.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Same rate with backtracking line search.
\end_layout

\begin_layout Standard
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{Based on 
\backslash
url{https://www.cs.cmu.edu/~ggordon/10725-F12/slides/05-gd-revisited.pdf}}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Convergence Rates for GD with Strong Convexity
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Definition
A differentiable function 
\begin_inset Formula $f$
\end_inset

 is strongly convex if there is some 
\begin_inset Formula $d>0$
\end_inset

 for which
\begin_inset Formula 
\[
f(y)\ge f(x)+\del f(x)^{T}(y-x)+\frac{d}{2}\|y-x\|^{2}\mbox{ all }x,y.
\]

\end_inset

(e.g.
 ridge regression because of the 
\begin_inset Formula $\ell_{2}$
\end_inset

 regularization term)
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Theorem
Under same Lipschitz condition as before and strong convexity, GD with fixed
 step size or with backtracking line search satisfies
\begin_inset Formula 
\[
f(x^{(k)})-f(x^{*})\le c^{k}\frac{L}{2}\|x^{(0)}-x^{*}\|^{2},
\]

\end_inset

where 
\begin_inset Formula $0<c<1$
\end_inset

.
\end_layout

\begin_layout Standard
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{Based on 
\backslash
url{https://www.cs.cmu.edu/~ggordon/10725-F12/slides/05-gd-revisited.pdf}}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Convergence Rates for GD with Strong Convexity
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Theorem
Under same Lipschitz condition as before and strong convexity, GD with fixed
 step size or with backtracking line search satisfies
\begin_inset Formula 
\[
f(x^{(k)})-f(x^{*})\le c^{k}\frac{L}{2}\|x^{(0)}-x^{*}\|^{2},
\]

\end_inset

where 
\begin_inset Formula $0<c<1$
\end_inset

.
\end_layout

\begin_layout Itemize
So with strong convexity, GD converges at rate 
\begin_inset Formula $O(c^{k})$
\end_inset

.
 (exponentially fast!)
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
To get 
\begin_inset Formula $f(x^{(k)})-f(x^{*})\le\eps$
\end_inset

, need 
\begin_inset Formula $O(\log\left[1/\eps\right])$
\end_inset

 iterations.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Called 
\begin_inset Quotes eld
\end_inset


\series bold
linear convergence
\series default

\begin_inset Quotes erd
\end_inset

 because looks linear on semi-log plot.
 
\end_layout

\begin_layout Standard
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{Based on 
\backslash
url{https://www.cs.cmu.edu/~ggordon/10725-F12/slides/05-gd-revisited.pdf}}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
SGD vs GD on Log Scale
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Note Note
status open

\begin_layout Plain Layout
NOTE: Can we verify that iteration refers to something reasonable to make
 SGD and GD comparable?
\end_layout

\end_inset


\begin_inset Graphics
	filename ../Figures/optimization-rates/sgd-vs-gd-ridge-logistic.png
	lyxscale 50
	height 65theight%

\end_inset

 
\end_layout

\begin_layout Itemize
Shows l
\series bold
inear convergence
\series default
 for 
\begin_inset Quotes eld
\end_inset

Full
\begin_inset Quotes erd
\end_inset

 GD; 
\series bold
sublinear
\series default
 for others.
 
\end_layout

\begin_layout Itemize
Note: logarithmic y-axis
\end_layout

\begin_layout Standard
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{Figure from 
\backslash
url{http://www.stat.cmu.edu/~ryantibs/convexopt/lectures/25-fast-stochastic.pdf}}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
SGD is Slow Close to the Optimum – Does it Matter?
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
TRON is a 2nd order method (very fast close to the optimum)
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename /Users/drosen/Dropbox/repos/mlcourse/Figures/optimization-rates/optimizationerr-vs-risk.png
	lyxscale 50
	height 60theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{Plots from Bottou and Bousquet's "The Tradeoffs of Large Scale Learning."}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\end_body
\end_document
