#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin /Users/drosen/Dropbox/repos/mlcourse/Notes/
\textclass paper
\use_default_options false
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding iso8859-1
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing single
\use_hyperref false
\papersize letterpaper
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 0
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1.15in
\topmargin 0.71in
\rightmargin 1.15in
\bottommargin 0.71in
\secnumdepth 5
\tocdepth 5
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\reals}{\mathbf{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\integers}{\mathbf{Z}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\naturals}{\mathbf{N}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rationals}{\mathbf{Q}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ca}{\mathcal{A}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cb}{\mathcal{B}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cc}{\mathcal{C}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cd}{\mathcal{D}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ce}{\mathcal{E}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cf}{\mathcal{F}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cg}{\mathcal{G}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ch}{\mathcal{H}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ci}{\mathcal{I}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cj}{\mathcal{J}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ck}{\mathcal{K}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cl}{\mathcal{L}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cm}{\mathcal{M}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cn}{\mathcal{N}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\co}{\mathcal{O}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cp}{\mathcal{P}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cq}{\mathcal{Q}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\calr}{\mathcal{R}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cs}{\mathcal{S}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ct}{\mathcal{T}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cu}{\mathcal{U}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cv}{\mathcal{V}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cw}{\mathcal{W}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cx}{\mathcal{X}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cy}{\mathcal{Y}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cz}{\mathcal{Z}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ind}[1]{1(#1)}
\end_inset


\begin_inset FormulaMacro
\newcommand{\pr}{\mathbb{P}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\predsp}{\cy}
\end_inset


\begin_inset FormulaMacro
\newcommand{\outsp}{\cy}
\end_inset


\begin_inset FormulaMacro
\newcommand{\prxy}{P_{\cx\times\cy}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\prx}{P_{\cx}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\prygivenx}{P_{\cy\mid\cx}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ex}{\mathbb{E}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\var}{\textrm{Var}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\cov}{\textrm{Cov}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\sgn}{\textrm{sgn}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\sign}{\textrm{sign}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\kl}{\textrm{KL}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\law}{\mathcal{L}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\eps}{\varepsilon}
\end_inset


\begin_inset FormulaMacro
\newcommand{\as}{\textrm{ a.s.}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\io}{\textrm{ i.o.}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ev}{\textrm{ ev.}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\convd}{\stackrel{d}{\to}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\eqd}{\stackrel{d}{=}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\del}{\nabla}
\end_inset


\begin_inset FormulaMacro
\newcommand{\loss}{V}
\end_inset


\begin_inset FormulaMacro
\newcommand{\risk}{R}
\end_inset


\begin_inset FormulaMacro
\newcommand{\emprisk}{\hat{R}_{\ell}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\lossfnl}{L}
\end_inset


\begin_inset FormulaMacro
\newcommand{\emplossfnl}{\hat{L}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\empminimizer}[1]{\hat{#1}_{\ell}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\minimizer}[1]{#1_{*}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\etal}{\textrm{et. al.}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\tr}{\operatorname{tr}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\trace}{\operatorname{trace}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\diag}{\text{diag}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\rank}{\text{rank}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\linspan}{\text{span}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\proj}{\text{Proj}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\argmax}{\operatornamewithlimits{arg\, max}}
{\mbox{argmax}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\argmin}{\operatornamewithlimits{arg\, min}}
{\mbox{argmin}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\bfx}{\mathbf{x}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\bfy}{\mathbf{y}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\bfl}{\mathbf{\lambda}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\bfm}{\mathbf{\mu}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\calL}{\mathcal{L}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vw}{\boldsymbol{w}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vx}{\boldsymbol{x}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vxi}{\boldsymbol{\xi}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\valpha}{\boldsymbol{\alpha}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vbeta}{\boldsymbol{\beta}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vsigma}{\boldsymbol{\sigma}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vmu}{\boldsymbol{\mu}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vtheta}{\boldsymbol{\theta}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vd}{\boldsymbol{d}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vs}{\boldsymbol{s}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vt}{\boldsymbol{t}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vh}{\boldsymbol{h}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ve}{\boldsymbol{e}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vf}{\boldsymbol{f}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vg}{\boldsymbol{g}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vz}{\boldsymbol{z}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vk}{\boldsymbol{k}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\va}{\boldsymbol{a}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vb}{\boldsymbol{b}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vv}{\boldsymbol{v}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vy}{\boldsymbol{y}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\hil}{\ch}
\end_inset


\begin_inset FormulaMacro
\newcommand{\rkhs}{\hil}
\end_inset

 
\end_layout

\begin_layout Title
Linear Support Vector Machines
\end_layout

\begin_layout Author
David S.
 Rosenberg
\end_layout

\begin_layout Section
The Support Vector Machine
\end_layout

\begin_layout Standard
For a linear support vector machine (SVM), we use the hypothesis space of
 affine functions
\begin_inset Formula 
\[
\cf=\left\{ f(x)=w^{T}x+b\mid w\in\reals^{d},b\in\reals\right\} 
\]

\end_inset

and evaluate them with respect to the 
\series bold
SVM loss function
\series default
, also known as the 
\series bold
hinge loss
\series default
.
 The hinge loss is a margin loss defined as 
\begin_inset Formula $\ell(m)=\left(1-m\right)_{+}$
\end_inset

, where 
\begin_inset Formula $m=yf(x)$
\end_inset

 is the margin for the prediction function 
\begin_inset Formula $f$
\end_inset

 on the example 
\begin_inset Formula $(x,y)$
\end_inset

, and 
\begin_inset Formula $\left(x\right)_{+}=x\ind{x\ge0}$
\end_inset

 denotes the 
\begin_inset Quotes eld
\end_inset

positive part
\begin_inset Quotes erd
\end_inset

 of 
\begin_inset Formula $x$
\end_inset

.
 The SVM traditionally uses an 
\begin_inset Formula $\ell_{2}$
\end_inset

regularization term, and the objective function is written as
\begin_inset Formula 
\[
J(w,b)=\frac{1}{2}||w||^{2}+\frac{c}{n}\sum_{i=1}^{n}\left(1-y_{i}\left[w^{T}x_{i}+b\right]\right)_{+}.
\]

\end_inset

Note that the 
\begin_inset Formula $w$
\end_inset

 parameter is regularized, while the bias term 
\begin_inset Formula $b$
\end_inset

 is not regularized.
 An alternative approach (which saves some writing), is to drop the 
\begin_inset Formula $b$
\end_inset

 and add a a constant feature, say with the value 
\begin_inset Formula $1$
\end_inset

, to the representation of 
\begin_inset Formula $x$
\end_inset

.
 With this approach, the bias term will be regularized along with the rest
 of the parameters.
\end_layout

\begin_layout Standard
Rather than the typical 
\begin_inset Formula $\lambda$
\end_inset

 regularization parameter attached to the 
\begin_inset Formula $\ell_{2}$
\end_inset

 penalty, for SVMs it's traditional to have a 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $c$
\end_inset


\begin_inset Quotes erd
\end_inset

 parameter attached to the empirical risk component.
 The larger 
\begin_inset Formula $c$
\end_inset

 is, the more relative importance we attach to minimizing the empirical
 risk compared to finding a 
\begin_inset Quotes eld
\end_inset

simple
\begin_inset Quotes erd
\end_inset

 hypothesis with small 
\begin_inset Formula $\ell_{2}$
\end_inset

-norm.
 
\end_layout

\begin_layout Section
Formulating SVM as a QP
\end_layout

\begin_layout Standard
The SVM optimization problem is
\begin_inset Formula 
\begin{equation}
\min_{w\in\reals^{d},b\in\reals}\frac{1}{2}||w||^{2}+\frac{c}{n}\sum_{i=1}^{n}\left(1-y_{i}\left[w^{T}x_{i}+b\right]\right)_{+}.\label{eq:svm-orig-problem}
\end{equation}

\end_inset

This is an unconstrained optimization problem (which is nice), but the objective
 function is not differentiable, which makes it difficult to work with.
 We can formulate an equivalent problem with a differentiable objective,
 but we'll have to add new constraints to do so.
 Note that 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:svm-orig-problem"

\end_inset

is equivalent to
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\textrm{minimize} &  & \frac{1}{2}||w||^{2}+\frac{c}{n}\sum_{i=1}^{n}\xi_{i}\\
\textrm{subject to} &  & \xi_{i}\ge\left(1-y_{i}\left[w^{T}x_{i}+b\right]\right)_{+},
\end{eqnarray*}

\end_inset

since the minimization will always drive down 
\begin_inset Formula $\xi_{i}$
\end_inset

 until 
\begin_inset Formula $\xi_{i}^{*}=\left(1-y_{i}\left[w^{T}x_{i}+b\right]\right)_{+}$
\end_inset

.
 We can now break up the inequality into two parts: 
\begin_inset Formula 
\begin{eqnarray*}
\textrm{minimize} &  & \frac{1}{2}||w||^{2}+\frac{c}{n}\sum_{i=1}^{n}\xi_{i}\\
\textrm{subject to} &  & \xi_{i}\ge0\;\mbox{for }i=1,\ldots,n\\
 &  & \xi_{i}\ge\left(1-y_{i}\left[w^{T}x_{i}+b\right]\right)\;\mbox{for }i=1,\ldots,n
\end{eqnarray*}

\end_inset

We now have a differentiable objective function in 
\begin_inset Formula $d+1+n$
\end_inset

 variables with 
\begin_inset Formula $2n$
\end_inset

 affine constraints.
 This is a quadratic program that can be solved by any off-the-shelf QP
 solver.
 
\end_layout

\begin_layout Section
Compute the Lagrangian Dual
\end_layout

\begin_layout Standard
The Lagrangian for this formulation is 
\begin_inset Formula 
\begin{align*}
L(w,b,\xi,\alpha,\lambda)= & \frac{1}{2}||w||^{2}+\frac{c}{n}\sum_{i=1}^{n}\xi_{i}+\sum_{i=1}^{n}\alpha_{i}\left(1-y_{i}\left[w^{T}x_{i}+b\right]-\xi_{i}\right)-\sum_{i=1}^{n}\lambda_{i}\xi_{i}\\
= & \frac{1}{2}w^{T}w+\sum_{i=1}^{n}\xi_{i}\left(\frac{c}{n}-\alpha_{i}-\lambda_{i}\right)+\sum_{i=1}^{n}\alpha_{i}\left(1-y_{i}\left[w^{T}x_{i}+b\right]\right).
\end{align*}

\end_inset

From our study of Lagrangian duality, we know that the original problem
 can now be expressed as
\begin_inset Formula 
\[
\inf_{w,b,\xi}\sup_{\alpha,\lambda\succeq0}L(w,b,\xi,\alpha,\lambda).
\]

\end_inset

Since our constraints are affine, by Slater's condition we have strong duality
 so long as the problem is feasible (i.e.
 so long as there is at least one point in the feasible set).
 The constraints are satisfied by 
\begin_inset Formula $w=0$
\end_inset

 and 
\begin_inset Formula $\xi_{i}=1$
\end_inset

 for 
\begin_inset Formula $i=1,\ldots,n$
\end_inset

, so 
\series bold
we have strong duality
\series default
.
 Thus we get the same result if we solve the following dual problem:
\begin_inset Formula 
\[
\sup_{\alpha,\lambda\succeq0}\inf_{w,b,\xi}L(w,b,\xi,\alpha,\lambda).
\]

\end_inset


\end_layout

\begin_layout Standard
As usual, we capture the inner optimization in the Lagrange dual objective:
 
\begin_inset Formula $g(\alpha,\lambda)=\inf_{w,\xi}L(w,b,\xi,\alpha,\lambda)$
\end_inset

 .
 Note that if 
\begin_inset Formula $\frac{c}{n}-\alpha_{i}-\lambda_{i}\neq0$
\end_inset

, then the Lagrangian is unbounded below (by taking 
\begin_inset Formula $\xi_{i}\to\pm\infty$
\end_inset

) and thus the infimum is 
\begin_inset Formula $-\infty$
\end_inset

.
 For any given 
\begin_inset Formula $\left(\alpha,\lambda\right)$
\end_inset

, the function 
\begin_inset Formula $\left(w,\xi\right)\mapsto L(w,b,\xi,\alpha,\lambda)$
\end_inset

 is differentiable and convex, thus we have an optimal point if and only
 if all partial derivatives of 
\begin_inset Formula $L$
\end_inset

 with respect to 
\begin_inset Formula $w$
\end_inset

, 
\begin_inset Formula $b$
\end_inset

, and 
\begin_inset Formula $\xi$
\end_inset

 are 0:
\begin_inset Formula 
\begin{eqnarray}
\partial_{w}L=0 & \iff & w-\sum_{i=1}^{n}\alpha_{i}y_{i}x_{i}=0\;\iff\;w=\sum_{i=1}^{n}\alpha_{i}y_{i}x_{i}\label{eq:lagrangeDeriv_w}\\
\partial_{b}L=0 & \iff & -\sum_{i=1}^{n}\alpha_{i}y_{i}=0\;\iff\;\sum_{i=1}^{n}\alpha_{i}y_{i}=0\nonumber \\
\partial_{\xi_{i}}L=0 & \iff & \frac{c}{n}-\alpha_{i}-\lambda_{i}=0\;\iff\;\alpha_{i}+\lambda_{i}=\frac{c}{n}
\end{eqnarray}

\end_inset

Note that one of the conditions is 
\begin_inset Formula $\alpha_{i}+\lambda_{i}=\frac{c}{n}$
\end_inset

, which agrees with our previous observation that if 
\begin_inset Formula $\alpha_{i}+\lambda_{i}\neq\frac{c}{n}$
\end_inset

 then 
\begin_inset Formula $L$
\end_inset

 is unbounded below.
 
\end_layout

\begin_layout Standard
Substituting these conditions back into 
\begin_inset Formula $L$
\end_inset

, the second term disappears, while the first and third terms become
\begin_inset Formula 
\begin{eqnarray*}
\frac{1}{2}w^{T}w & = & \frac{1}{2}\sum_{i,j=1}^{n}\alpha_{i}\alpha_{j}y_{i}y_{j}x_{i}^{T}x_{j}\\
\sum_{i=1}^{n}\alpha_{i}(1-y_{i}\left[w^{T}x_{i}+b\right]) & = & \sum_{i=1}^{n}\alpha_{i}-\sum_{i,j=1}^{n}\alpha_{i}\alpha_{j}y_{i}y_{j}x_{j}^{T}x_{i}-b\underbrace{\sum_{i=1}^{n}\alpha_{i}y_{i}}_{=0}.
\end{eqnarray*}

\end_inset

In the last expression, we see that if 
\begin_inset Formula $\sum_{i=1}^{n}\alpha_{i}y_{i}\neq0$
\end_inset

, then by sending 
\begin_inset Formula $b$
\end_inset

 to 
\begin_inset Formula $\pm\infty$
\end_inset

, we can send the dual function to 
\begin_inset Formula $-\infty$
\end_inset

.
\end_layout

\begin_layout Standard
Putting it together, the dual function is 
\begin_inset Formula 
\[
g(\alpha,\lambda)=\begin{cases}
\sum_{i=1}^{n}\alpha_{i}-\frac{1}{2}\sum_{i,j=1}^{n}\alpha_{i}\alpha_{j}y_{i}y_{j}x_{j}^{T}x_{i} & \sum_{i=1}^{n}\alpha_{i}y_{i}=0,\,\alpha_{i}+\lambda_{i}=\frac{c}{n}\mbox{, all }i\\
-\infty & \mbox{otherwise.}
\end{cases}
\]

\end_inset

Thus we can write the dual problem as
\begin_inset Formula 
\begin{align*}
\sup_{\alpha,\lambda} & \sum_{i=1}^{n}\alpha_{i}-\frac{1}{2}\sum_{i,j=1}^{n}\alpha_{i}\alpha_{j}y_{i}y_{j}x_{j}^{T}x_{i}\\
\mbox{s.t.} & \sum_{i=1}^{n}\alpha_{i}y_{i}=0\\
 & \alpha_{i}+\lambda_{i}=\frac{c}{n},\,i=1,\ldots,n\\
 & \alpha_{i},\lambda_{i}\ge0,\,i=1,\ldots,n
\end{align*}

\end_inset

We can actually eliminate the 
\begin_inset Formula $\lambda$
\end_inset

 variables, replacing the last three constraints by 
\begin_inset Formula $0\le\alpha_{i}\le\frac{c}{n}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
\sup_{\alpha} & \sum_{i=1}^{n}\alpha_{i}-\frac{1}{2}\sum_{i,j=1}^{n}\alpha_{i}\alpha_{j}y_{i}y_{j}x_{j}^{T}x_{i}\\
\mbox{s.t.} & \sum_{i=1}^{n}\alpha_{i}y_{i}=0\\
 & \alpha_{i}\in\left[0,\frac{c}{n}\right].
\end{align*}

\end_inset

When written in standard form, this has a quadratic objective in 
\begin_inset Formula $n$
\end_inset

 unknowns and 
\begin_inset Formula $2n+1$
\end_inset

 constraints.
 The constraints of the form 
\begin_inset Formula $\alpha_{i}\in\left[0,\frac{c}{n}\right]$
\end_inset

 are called 
\series bold
box constraints
\series default
, and are particularly easy to handle in optimization.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\left(w^{*},b^{*},\xi^{*}\right)$
\end_inset

 be a solution to the primal problem, and let 
\begin_inset Formula $\left(\alpha^{*},\lambda^{*}\right)$
\end_inset

 be a solution to the dual problem.
 Then by strong duality and since everything is differentiable, the solutions
 must obey the KKT conditions.
 In particular, the solutions must satisfy the first order condition we
 derived in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:lagrangeDeriv_w"

\end_inset

.
 So 
\begin_inset Formula 
\[
w^{*}=\sum_{i=1}^{n}\alpha_{i}^{*}y_{i}x_{i}.
\]

\end_inset

 
\end_layout

\begin_layout Itemize
Note that 
\begin_inset Formula $w^{*}=\sum_{i=1}^{n}\alpha_{i}^{*}y_{i}x_{i}$
\end_inset

 only depends on those examples for which 
\begin_inset Formula $\alpha_{i}^{*}>0$
\end_inset

 (recall that 
\begin_inset Formula $\alpha_{i}^{*}\ge0$
\end_inset

 by constraint).
 These examples are called 
\series bold
support vectors
\series default
.
 
\end_layout

\begin_layout Itemize
Since 
\begin_inset Formula $\alpha_{i}\in[0,\frac{c}{n}]$
\end_inset

, we see that 
\begin_inset Formula $c$
\end_inset

 controls the amount of weight we can put on any single example.
 
\end_layout

\begin_layout Standard
Note that we still don't have an expression for the optimal bias term 
\begin_inset Formula $b^{*}$
\end_inset

.
 We'll derive this below using complementary slackness conditions.
\end_layout

\begin_layout Section
Consequences of Complementary Slackness 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\left(w^{*},b^{*},\xi_{i}^{*}\right)$
\end_inset

 and 
\begin_inset Formula $\left(\alpha^{*},\lambda^{*}\right)$
\end_inset

 be optimal solutions to the primal and dual problems, respectively.
 For notational convenience, let's define 
\begin_inset Formula $f^{*}(x)=x_{i}^{T}w^{*}+b^{*}$
\end_inset

.
 By strong duality, we have the following 
\series bold
complementary slackness
\series default
 conditions:
\begin_inset Formula 
\begin{align}
\alpha_{i}^{*}\left(1-y_{i}f^{*}(x_{i})-\xi_{i}^{*}\right) & =0\label{eq:lossNonNegativeSlackCondition}\\
\lambda_{i}^{*}\xi_{i}^{*}=\left(\frac{c}{n}-\alpha_{i}^{*}\right)\xi_{i}^{*} & =0\label{eq:marginLossSlackCondition}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
We now draw many straightforward conclusions:
\end_layout

\begin_layout Itemize
As we noted above, 
\begin_inset Formula $\xi_{i}^{*}$
\end_inset

 is the hinge loss on example 
\begin_inset Formula $i$
\end_inset

.
 When 
\begin_inset Formula $\xi_{i}^{*}=0$
\end_inset

, we're either 
\begin_inset Quotes eld
\end_inset

at the margin
\begin_inset Quotes erd
\end_inset

 (i.e.
 
\begin_inset Formula $y_{i}f^{*}(x_{i})=1$
\end_inset

) or on the 
\begin_inset Quotes eld
\end_inset

good side of the margin
\begin_inset Quotes erd
\end_inset

 (
\begin_inset Formula $y_{i}f^{*}(x_{i})>1$
\end_inset

).
 That is
\begin_inset Formula 
\begin{equation}
\xi_{i}^{*}=0\implies y_{i}f^{*}(x_{i})\ge1.\label{eq:hingeLoss0meansAtMarginOrBetter}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
By 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:marginLossSlackCondition"

\end_inset

, 
\begin_inset Formula $\alpha_{i}^{*}=0$
\end_inset

 implies 
\begin_inset Formula $\xi_{i}^{*}=0$
\end_inset

, which by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:hingeLoss0meansAtMarginOrBetter"

\end_inset

 implies 
\begin_inset Formula $y_{i}f^{*}(x)\ge1$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\alpha_{i}^{*}\in\left(0,\frac{c}{n}\right)$
\end_inset

 implies 
\begin_inset Formula $\xi_{i}^{*}=0$
\end_inset

, by 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:marginLossSlackCondition"

\end_inset

.
 Then by 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:lossNonNegativeSlackCondition"

\end_inset

 we get 
\begin_inset Formula $y_{i}f^{*}(x_{i})=1$
\end_inset

.
 So the prediction is right on the margin.
 
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $y_{i}f^{*}(x_{i})<1$
\end_inset

 then the margin loss is 
\begin_inset Formula $\xi_{i}^{*}>0$
\end_inset

, and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:marginLossSlackCondition"

\end_inset

 implies that 
\begin_inset Formula $\alpha_{i}^{*}=\frac{c}{n}$
\end_inset

.
 
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $y_{i}f^{*}(x)>1$
\end_inset

 then the margin loss is 
\begin_inset Formula $\xi_{i}^{*}=0$
\end_inset

, and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:lossNonNegativeSlackCondition"

\end_inset

 implies 
\begin_inset Formula $\alpha_{i}^{*}=0$
\end_inset

.
\end_layout

\begin_layout Itemize
The contrapositive of the previous result is that 
\begin_inset Formula $\alpha_{i}^{*}>0$
\end_inset

 implies 
\begin_inset Formula $y_{i}f^{*}(x)\le1$
\end_inset

.
 This seems to be all we can say for the specific case 
\begin_inset Formula $\alpha_{i}^{*}=\frac{c}{n}$
\end_inset

.
 
\end_layout

\begin_layout Itemize
We also can't draw any extra information about 
\begin_inset Formula $\alpha_{i}^{*}$
\end_inset

 for points exactly on the margin (
\begin_inset Formula $y_{i}f^{*}(x_{i})=1$
\end_inset

).
 
\end_layout

\begin_layout Standard
We summarize these results below: 
\begin_inset Formula 
\begin{eqnarray*}
\alpha_{i}^{*}=0 & \implies & y_{i}f^{*}(x_{i})\ge1\\
\alpha_{i}^{*}\in\left(0,\frac{c}{n}\right) & \implies & y_{i}f^{*}(x_{i})=1\\
\alpha_{i}^{*}=\frac{c}{n} & \implies & y_{i}f^{*}(x_{i})\le1
\end{eqnarray*}

\end_inset


\begin_inset Formula 
\begin{eqnarray*}
y_{i}f^{*}(x_{i})<1 & \implies & \alpha_{i}^{*}=\frac{c}{n}\\
y_{i}f^{*}(x_{i})=1 & \implies & \alpha_{i}^{*}\in\left[0,\frac{c}{n}\right]\\
y_{i}f^{*}(x_{i})>1 & \implies & \alpha_{i}^{*}=0
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Subsection
Determining 
\begin_inset Formula $b$
\end_inset


\end_layout

\begin_layout Standard
Finally, let's determine 
\begin_inset Formula $b$
\end_inset

.
 Suppose there exists an 
\begin_inset Formula $i$
\end_inset

 such that 
\begin_inset Formula $\alpha_{i}^{*}\in\left(0,\frac{c}{n}\right)$
\end_inset

.
 Then 
\begin_inset Formula $\xi_{i}^{*}=0$
\end_inset

 by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:marginLossSlackCondition"

\end_inset

 and by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:lossNonNegativeSlackCondition"

\end_inset

 we get 
\begin_inset Formula $y_{i}\left[x_{i}^{T}w^{*}+b^{*}\right]=1$
\end_inset

.
 Since 
\begin_inset Formula $y_{i}\in\left\{ -1,1\right\} $
\end_inset

, we can multiply on both sides by 
\begin_inset Formula $y_{i}$
\end_inset

 to conclude that 
\begin_inset Formula 
\[
b^{*}=y_{i}-x_{i}^{T}w^{*}.
\]

\end_inset


\end_layout

\begin_layout Standard
With exact calculations, we would get the same 
\begin_inset Formula $b^{*}$
\end_inset

 for any choice of 
\begin_inset Formula $i$
\end_inset

 with 
\begin_inset Formula $\alpha_{i}^{*}\in\left(0,\frac{c}{n}\right)$
\end_inset

.
 With numerical error, however, some people suggest averaging over all eligible
 
\begin_inset Formula $i$
\end_inset

's:
\begin_inset Formula 
\[
b^{*}=\text{mean}\left\{ y_{i}-x_{i}^{T}w^{*}\mid\alpha_{i}^{*}\in\left(0,\frac{c}{n}\right)\right\} .
\]

\end_inset


\end_layout

\begin_layout Standard
If there are no 
\begin_inset Formula $\alpha_{i}^{*}\in\left(0,\frac{c}{n}\right)$
\end_inset

, then we have a 
\series bold
degenerate SVM training problem
\series default

\begin_inset Foot
status open

\begin_layout Plain Layout
This is shown in Rifkin et al.'s 
\begin_inset Quotes eld
\end_inset

A Note on Support Vector Machine Degeneracy
\begin_inset Quotes erd
\end_inset

, an MIT AI Lab Technical Report.
\end_layout

\end_inset

, for which 
\begin_inset Formula $w^{*}=0$
\end_inset

, and we always predict the majority class.
\end_layout

\end_body
\end_document
